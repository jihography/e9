{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f1e943",
   "metadata": {},
   "source": [
    "### 수출입통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6443cf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined CSV to: /Users/kjh/Documents/geostat3_e9/trade_panel_2008_2025.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/kjh/Documents/geostat3_e9/trade_panel_2008_2025.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retry: save CSV only (parquet engine not available in this environment) and show a preview table.\n",
    "import os, pandas as pd\n",
    "\n",
    "csv_path = \"/Users/kjh/Documents/geostat3_e9/trade_panel_2008_2025.csv\"\n",
    "# 'combined' may not exist if the previous cell errored before creation; rebuild quickly.\n",
    "import re, numpy as np\n",
    "from glob import glob\n",
    "\n",
    "def read_any_encoding(path, **kwargs):\n",
    "    try:\n",
    "        return pd.read_csv(path, **kwargs)\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(path, encoding=\"cp949\", **kwargs)\n",
    "\n",
    "base = \"/Users/kjh/Documents/geostat3_e9/data/\"\n",
    "paths = sorted(glob(os.path.join(base, \"export_*.csv\")))\n",
    "\n",
    "frames = []\n",
    "for p in paths:\n",
    "    m = re.search(r\"export_(\\d{4})\\.csv$\", os.path.basename(p))\n",
    "    year_from_name = int(m.group(1)) if m else None\n",
    "    df = read_any_encoding(p)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    if \"기간\" in df.columns:\n",
    "        df = df[df[\"기간\"].astype(str).str.strip() != \"총계\"].copy()\n",
    "        df[\"time\"] = pd.to_datetime(df[\"기간\"], format=\"%Y-%m\", errors=\"coerce\")\n",
    "    else:\n",
    "        df[\"time\"] = pd.NaT\n",
    "    if \"지역\" in df.columns:\n",
    "        df = df.rename(columns={\"지역\":\"region\"})\n",
    "    else:\n",
    "        df[\"region\"] = np.nan\n",
    "    ren = {\"수출 건수\":\"export_cnt\",\"수출 금액\":\"export_val\",\"수입 건수\":\"import_cnt\",\"수입 금액\":\"import_val\",\"무역수지\":\"trade_balance\"}\n",
    "    for k,v in ren.items():\n",
    "        if k in df.columns:\n",
    "            df = df.rename(columns={k:v})\n",
    "    keep = [\"time\",\"region\",\"export_cnt\",\"export_val\",\"import_cnt\",\"import_val\",\"trade_balance\"]\n",
    "    for k in keep:\n",
    "        if k not in df.columns:\n",
    "            df[k] = np.nan\n",
    "    out = df[keep].copy()\n",
    "    out[\"year\"] = out[\"time\"].dt.year\n",
    "    out[\"month\"] = out[\"time\"].dt.month\n",
    "    out[\"file_year\"] = year_from_name\n",
    "    frames.append(out)\n",
    "\n",
    "combined = pd.concat(frames, ignore_index=True).drop_duplicates().sort_values([\"time\"]).reset_index(drop=True)\n",
    "combined.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Saved combined CSV to:\", csv_path)\n",
    "csv_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd4b83",
   "metadata": {},
   "source": [
    "### 제조업생산지수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07216c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/snustdatasci-2025/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "# Parse the specific header style (e.g., 'M200801 2008.01') and reshape to long.\n",
    "import pandas as pd, numpy as np, re\n",
    "\n",
    "path = \"/Users/kjh/Documents/geostat3_e9/data/시도_재별_제조업생산지수_2020100__20251103235729.xlsx\"\n",
    "sheet = \"데이터\"\n",
    "\n",
    "df = pd.read_excel(path, sheet_name=sheet, header=0, dtype=str)\n",
    "df = df.dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "df.columns = [str(c).strip() for c in df.columns]\n",
    "\n",
    "# Identify columns\n",
    "region_col = next((c for c in df.columns if \"시도\" in c), df.columns[0])\n",
    "class_col  = next((c for c in df.columns if \"재별\" in c or \"분류\" in c), None)\n",
    "\n",
    "# Period columns like 'M200801 2008.01'\n",
    "period_cols = [c for c in df.columns if re.match(r'^M\\d{6}\\s+\\d{4}\\.\\d{2}$', c)]\n",
    "\n",
    "# Create a mapping from col -> datetime\n",
    "def col_to_time(col):\n",
    "    m = re.match(r'^M(\\d{6})\\s+(\\d{4})\\.(\\d{2})$', col)\n",
    "    if m:\n",
    "        yyyymm = m.group(1)\n",
    "        yyyy, mm = yyyymm[:4], yyyymm[4:]\n",
    "        return pd.Timestamp(f\"{yyyy}-{mm}-01\")\n",
    "    m2 = re.search(r'(\\d{4})(\\d{2})', col)  # fallback\n",
    "    if m2:\n",
    "        return pd.Timestamp(f\"{m2.group(1)}-{m2.group(2)}-01\")\n",
    "    return pd.NaT\n",
    "\n",
    "time_map = {c: col_to_time(c) for c in period_cols}\n",
    "\n",
    "# Keep subset & rename\n",
    "keep = [region_col] + ([class_col] if class_col else []) + period_cols\n",
    "wide = df[keep].copy().rename(\n",
    "    columns={region_col: \"region\", class_col: \"category\"} if class_col else {region_col: \"region\"}\n",
    ")\n",
    "\n",
    "# --- Clean region ---\n",
    "# 1) region 결측(빈 문자열 포함) 위→아래 채우기 (중간재/소비재 등 하위행에 지역 상속)\n",
    "wide[\"region\"] = wide[\"region\"].replace(r\"^\\s*$\", np.nan, regex=True).ffill()\n",
    "\n",
    "# 2) region 앞 숫자코드 제거 (예: \"00 전국\", \"11_서울특별시\" → \"전국\", \"서울특별시\")\n",
    "def clean_leading_code(s: str) -> str:\n",
    "    if s is None:\n",
    "        return s\n",
    "    s = str(s).strip()\n",
    "    s = re.sub(r'^\\s*\\d+\\s*[-_.]?\\s*', '', s)  # 선행 숫자(+구분자) 제거\n",
    "    return s.strip()\n",
    "\n",
    "wide[\"region\"] = wide[\"region\"].map(clean_leading_code)\n",
    "\n",
    "# 3) 전국 제외\n",
    "wide = wide[~wide[\"region\"].str.contains(r\"^전국$\", na=False)]\n",
    "\n",
    "# --- Clean category (숫자 코드 제거: \"1 중간재\" → \"중간재\") ---\n",
    "if \"category\" in wide.columns:\n",
    "    wide[\"category\"] = wide[\"category\"].fillna(\"\").astype(str).str.strip()\n",
    "    # 선행 숫자(+구분자/공백) 제거\n",
    "    wide[\"category\"] = wide[\"category\"].str.replace(r'^\\s*\\d+\\s*[-_.]?\\s*', '', regex=True).str.strip()\n",
    "    # 완전 빈값은 NaN으로\n",
    "    wide[\"category\"] = wide[\"category\"].replace({\"\": np.nan})\n",
    "\n",
    "# Melt\n",
    "id_vars = [\"region\"] + ([\"category\"] if \"category\" in wide.columns else [])\n",
    "long = wide.melt(id_vars=id_vars, var_name=\"col\", value_name=\"manufacturing_production_index\")\n",
    "\n",
    "# Map to datetime\n",
    "long[\"time\"] = long[\"col\"].map(time_map)\n",
    "long = long.dropna(subset=[\"time\"]).copy()\n",
    "\n",
    "# Clean values\n",
    "vals = long[\"manufacturing_production_index\"].astype(str).str.replace(\",\", \"\", regex=False).str.strip()\n",
    "vals = vals.replace({\"\": np.nan, \"-\": np.nan})\n",
    "long[\"manufacturing_production_index\"] = pd.to_numeric(vals, errors=\"coerce\")\n",
    "\n",
    "# Tidy\n",
    "long[\"region\"] = long[\"region\"].astype(str).str.strip()\n",
    "if \"category\" in long.columns:\n",
    "    long[\"category\"] = long[\"category\"].astype(\"string\")\n",
    "long[\"year\"] = long[\"time\"].dt.year.astype(\"Int64\")\n",
    "long[\"month\"] = long[\"time\"].dt.month.astype(\"Int64\")\n",
    "long[\"series_name\"] = \"제조업생산지수(2020=100)\"\n",
    "\n",
    "# Sort\n",
    "sort_keys = [\"region\", \"time\"]\n",
    "if \"category\" in long.columns:\n",
    "    sort_keys = [\"region\", \"category\", \"time\"]\n",
    "long = long.sort_values(sort_keys).reset_index(drop=True)\n",
    "\n",
    "out_csv = \"/Users/kjh/Documents/geostat3_e9/manufacturing_production_index_long.csv\"\n",
    "long.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc0af713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kjh/Documents/geostat3_e9'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c52ed87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/snustdatasci-2025/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/miniconda3/envs/snustdatasci-2025/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/miniconda3/envs/snustdatasci-2025/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/miniconda3/envs/snustdatasci-2025/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/miniconda3/envs/snustdatasci-2025/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/opt/miniconda3/envs/snustdatasci-2025/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "# Build a unified labor-force panel with T1, T2, ... metrics as separate columns (wide by metric).\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/Users/kjh/Documents/geostat3_e9/data\")\n",
    "paths = [BASE / f\"labor_force_{i}.xlsx\" for i in range(1,7)]\n",
    "\n",
    "# Regexes for KOSIS header patterns\n",
    "RX_Y = re.compile(r\"^Y(?P<code>\\d{4})\\s+(?P<year>\\d{4})(?:\\.(?P<sub>\\d+))?$\")\n",
    "RX_H = re.compile(r\"^H(?P<code>\\d{6})\\s+(?P<year>\\d{4})\\.(?P<half>[12])\\/2(?:\\.(?P<sub>\\d+))?$\")\n",
    "RX_Q = re.compile(r\"^Q(?P<code>\\d{6})\\s+(?P<year>\\d{4})\\.(?P<q>[1-4])\\/4(?:\\.(?P<sub>\\d+))?$\")\n",
    "\n",
    "def parse_time(col):\n",
    "    s = str(col).strip()\n",
    "    m = RX_Y.match(s)\n",
    "    if m:\n",
    "        return {\"year\": int(m.group(\"year\")), \"month\": 12, \"freq\": \"A\", \"period\": 1}\n",
    "    m = RX_H.match(s)\n",
    "    if m:\n",
    "        y = int(m.group(\"year\")); h = int(m.group(\"half\"))\n",
    "        return {\"year\": y, \"month\": 6 if h==1 else 12, \"freq\":\"H\", \"period\": h}\n",
    "    m = RX_Q.match(s)\n",
    "    if m:\n",
    "        y = int(m.group(\"year\")); q = int(m.group(\"q\"))\n",
    "        return {\"year\": y, \"month\": {1:3,2:6,3:9,4:12}[q], \"freq\":\"Q\", \"period\": q}\n",
    "    return None\n",
    "\n",
    "def detect_region_col(df):\n",
    "    for key in [\"행정구역\", \"행정구역별\", \"시군구\", \"지역\"]:\n",
    "        hits = [c for c in df.columns if key in str(c)]\n",
    "        if hits:\n",
    "            return hits[0]\n",
    "    return df.columns[0]\n",
    "\n",
    "def extract_code_name(s):\n",
    "    s = str(s)\n",
    "    # Allow 4~5 digits prefix (예: 3101 수원시 / 11110 종로구)\n",
    "    m5 = re.search(r\"(\\d{5})\", s)\n",
    "    m4 = re.search(r\"(^|\\s)(\\d{4})(\\s|$)\", s)\n",
    "    code = m5.group(1) if m5 else (m4.group(2) if m4 else np.nan)\n",
    "    # Clean name\n",
    "    name = re.sub(r\"\\(\\d{4,5}\\)\", \"\", s)\n",
    "    name = re.sub(r\"\\b\\d{4,5}\\b\", \"\", name)\n",
    "    name = name.replace(\"\\u3000\", \" \")\n",
    "    name = re.sub(r\"\\s+\", \" \", name).strip()\n",
    "    return pd.Series({\"sgg_code\": code, \"sgg_name\": name})\n",
    "\n",
    "def get_metric_code(label_text):\n",
    "    s = str(label_text).strip()\n",
    "    m = re.match(r\"^(T\\d+)\", s)\n",
    "    return m.group(1) if m else s  # fallback to full label\n",
    "\n",
    "wide_frames = []\n",
    "logs = []\n",
    "\n",
    "for p in paths:\n",
    "    # Read with header row as row 0; assume sheet \"데이터\"\n",
    "    df = pd.read_excel(p, sheet_name=\"데이터\", dtype=str, engine=\"openpyxl\", header=0)\n",
    "    region_col = detect_region_col(df)\n",
    "    if df.empty or region_col not in df.columns:\n",
    "        logs.append({\"file\": p.name, \"status\":\"EMPTY_OR_NO_REGION\"})\n",
    "        continue\n",
    "    \n",
    "    # First row contains metric labels for time columns (KOSIS style)\n",
    "    label_row = df.iloc[0]\n",
    "    data = df.iloc[1:].copy()\n",
    "    \n",
    "    # Identify time columns by regex\n",
    "    time_cols = [c for c in data.columns if parse_time(c) is not None]\n",
    "    if not time_cols:\n",
    "        logs.append({\"file\": p.name, \"status\":\"NO_TIME_COLS\"})\n",
    "        continue\n",
    "    \n",
    "    # Melt to long with time meta\n",
    "    long = data.melt(id_vars=[region_col], value_vars=time_cols, var_name=\"time_col\", value_name=\"value\")\n",
    "    meta = pd.DataFrame([parse_time(c) for c in long[\"time_col\"]])\n",
    "    long = pd.concat([long, meta], axis=1)\n",
    "    # Attach metric code from label row\n",
    "    metric_map = {c: get_metric_code(label_row.get(c, \"\")) for c in time_cols}\n",
    "    long[\"metric\"] = long[\"time_col\"].map(metric_map)\n",
    "    # Clean region\n",
    "    region_df = long[region_col].apply(extract_code_name)\n",
    "    long = pd.concat([long, region_df], axis=1)\n",
    "    # Numeric\n",
    "    long[\"value\"] = (long[\"value\"].astype(str)\n",
    "                     .str.replace(\",\", \"\", regex=False)\n",
    "                     .replace({\"-\": np.nan, \"\": np.nan}))\n",
    "    long[\"value\"] = pd.to_numeric(long[\"value\"], errors=\"coerce\")\n",
    "    # Drop missing essentials\n",
    "    long = long.dropna(subset=[\"year\",\"month\",\"value\"])\n",
    "    # Cast\n",
    "    long[\"year\"] = long[\"year\"].astype(\"Int64\")\n",
    "    long[\"month\"] = long[\"month\"].astype(\"Int64\")\n",
    "    long[\"source_file\"] = p.name\n",
    "    \n",
    "    # Pivot: metrics into columns (T1, T2, ...)\n",
    "    wide = (long\n",
    "            .pivot_table(index=[\"sgg_code\",\"sgg_name\",\"year\",\"month\",\"freq\",\"period\",\"source_file\"],\n",
    "                         columns=\"metric\", values=\"value\", aggfunc=\"first\")\n",
    "            .reset_index())\n",
    "    # Sort metric columns naturally (T1, T2, ... then others)\n",
    "    metric_cols = [c for c in wide.columns if c not in [\"sgg_code\",\"sgg_name\",\"year\",\"month\",\"freq\",\"period\",\"source_file\"]]\n",
    "    def metric_key(c):\n",
    "        m = re.match(r\"^T(\\d+)$\", str(c))\n",
    "        return (0, int(m.group(1))) if m else (1, str(c))\n",
    "    metric_cols_sorted = sorted(metric_cols, key=metric_key)\n",
    "    wide = wide[[\"sgg_code\",\"sgg_name\",\"year\",\"month\",\"freq\",\"period\",\"source_file\"] + metric_cols_sorted]\n",
    "    wide_frames.append(wide)\n",
    "    logs.append({\"file\": p.name, \"status\":\"OK\", \"rows\": len(wide), \"metrics\": metric_cols_sorted[:10]})\n",
    "\n",
    "# Concatenate and unify\n",
    "panel_wide = pd.concat(wide_frames, ignore_index=True) if wide_frames else pd.DataFrame()\n",
    "\n",
    "# If the same (sgg, time) appears across files (e.g., overlapping), prefer later files by sorting by source_file then dropping duplicates\n",
    "panel_wide = panel_wide.sort_values([\"sgg_code\",\"sgg_name\",\"year\",\"month\",\"freq\",\"period\",\"source_file\"]).drop_duplicates(\n",
    "    subset=[\"sgg_code\",\"sgg_name\",\"year\",\"month\",\"freq\",\"period\"], keep=\"last\"\n",
    ")\n",
    "\n",
    "# Save and preview\n",
    "out_path = BASE / \"labor_force_panel_with_T_metrics.csv\"\n",
    "panel_wide.to_csv(out_path, index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddecbfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/kjh/Documents/geostat3_e9/data/labor_force_panel_named.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/Users/kjh/Documents/geostat3_e9/data\")\n",
    "\n",
    "in_path  = BASE / \"labor_force_panel_with_T_metrics.csv\"\n",
    "out_path = BASE / \"labor_force_panel_named.csv\"\n",
    "\n",
    "# 1) 로드\n",
    "df = pd.read_csv(in_path, dtype={\"sgg_code\": str})\n",
    "\n",
    "# 2) T-코드 → 읽기 쉬운 변수명 매핑\n",
    "t_to_en = {\n",
    "    \"T1\": \"pop15p\",        # 15세 이상 인구 (천명)\n",
    "    \"T2\": \"labor_force\",   # 경제활동인구 (천명)\n",
    "    \"T3\": \"employed\",      # 취업자 (천명)\n",
    "    \"T4\": \"unemployed\",    # 실업자 (천명)\n",
    "    \"T5\": \"nilf\",          # 비경제활동인구 (천명)\n",
    "    \"T6\": \"lfpr\",          # 경제활동참가율 (%)\n",
    "    \"T7\": \"emp_rate\",      # 고용률 (%)\n",
    "    \"T8\": \"unemp_rate\",    # 실업률 (%)\n",
    "}\n",
    "\n",
    "# 3) 존재하는 T컬럼만 매핑하여 새 컬럼 생성\n",
    "present = [c for c in t_to_en if c in df.columns]\n",
    "for tcol in present:\n",
    "    df[t_to_en[tcol]] = df[tcol]\n",
    "\n",
    "# 4) 컬럼 순서 정리 (키 → 새 변수 → 원본 T컬럼 → 기타)\n",
    "key_cols   = [\"sgg_code\",\"sgg_name\",\"year\",\"month\",\"freq\",\"period\",\"source_file\"]\n",
    "named_cols = [t_to_en[c] for c in present]\n",
    "orig_cols  = [c for c in present]  # 원본 T1..T8 보존하려면 유지, 삭제하려면 아래에서 drop\n",
    "other_cols = [c for c in df.columns if c not in (key_cols + named_cols + orig_cols)]\n",
    "\n",
    "ordered = key_cols + named_cols + orig_cols + other_cols\n",
    "ordered = [c for c in ordered if c in df.columns]  # 안전하게 필터\n",
    "\n",
    "df_named = df[ordered].copy()\n",
    "\n",
    "# (옵션) 원본 T컬럼 삭제하려면 다음 두 줄 사용\n",
    "# df_named = df_named.drop(columns=present, errors=\"ignore\")\n",
    "# ordered = [c for c in ordered if c not in present]\n",
    "\n",
    "# 5) 저장\n",
    "df_named.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ac432cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kjh/Documents/geostat3_e9'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f35a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] population_panel.csv saved: /Users/kjh/Documents/geostat3_e9/population_panel.csv\n",
      "[OK] population_panel_sgg_aggregated.csv saved: /Users/kjh/Documents/geostat3_e9/population_panel_sgg_aggregated.csv\n",
      "rows=41,980, cols=['sido_name', 'sigungu', 'year', 'month', 'total', 'male', 'female', 'yyyymm']\n",
      "[DEBUG] 포항시 예시: [{'sido_name': '경상북도', 'sigungu': '포항시', 'year': 2008, 'month': 12, 'total': 1016238.0, 'male': 516882.0, 'female': 499356.0, 'yyyymm': 200812}]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "인구 패널(월/연 데이터 결합) → '시군구' 단위로 재집계 (코드기반 일반구-시 접기)\n",
    "- '일반시 + 구' (도 소속)만 같은 연-월에서 '시'로 합산\n",
    "- '특별시/광역시/특별자치시'의 '구'는 그대로 유지\n",
    "- 입력(그대로 사용):\n",
    "    /Users/kjh/Documents/geostat3_e9/data/101_DT_1B040A3_20251104000738.csv  (월별)\n",
    "    /Users/kjh/Documents/geostat3_e9/data/행정구역_시군구_별__성별_인구수_20251104000919.xlsx (연별)\n",
    "- 중간 산출: population_panel.csv\n",
    "- 최종 산출: population_panel_sgg_aggregated.csv  (컬럼: sido_name, sigungu, year, month, total, male, female, yyyymm)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/Users/kjh/Documents/geostat3_e9/data\")\n",
    "CSV_MONTHLY  = BASE / \"101_DT_1B040A3_20251104000738.csv\"\n",
    "XLSX_YEARLY  = BASE / \"행정구역_시군구_별__성별_인구수_20251104000919.xlsx\"\n",
    "\n",
    "OUT_PANEL    = BASE.parent / \"population_panel.csv\"\n",
    "OUT_AGG      = BASE.parent / \"population_panel_sgg_aggregated.csv\"\n",
    "\n",
    "# 시도 코드→명 (신코드 포함)\n",
    "SIDO_MAP = {\n",
    "    \"11\":\"서울특별시\",\"26\":\"부산광역시\",\"27\":\"대구광역시\",\"28\":\"인천광역시\",\"29\":\"광주광역시\",\n",
    "    \"30\":\"대전광역시\",\"31\":\"울산광역시\",\"36\":\"세종특별자치시\",\"41\":\"경기도\",\n",
    "    \"42\":\"강원도\",\"43\":\"충청북도\",\"44\":\"충청남도\",\"45\":\"전라북도\",\n",
    "    \"46\":\"전라남도\",\"47\":\"경상북도\",\"48\":\"경상남도\",\"50\":\"제주특별자치도\",\n",
    "    \"51\":\"강원특별자치도\",\"52\":\"전북특별자치도\"\n",
    "}\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 0) 월별 원시 CSV에서 '일반시의 구' → 부모 '시'를 코드로 찾는 매핑 구축\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def build_general_city_ward_code_map(csv_path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    반환: { five_digit_sgg_code(str) : parent_city_name(str) }\n",
    "    예) {\"47111\":\"포항시\",\"47113\":\"포항시\", \"41111\":\"수원시\", ...}\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, dtype=str, encoding=\"cp949\")\n",
    "    code_col = \"[A]행정구역(시군구)별\"\n",
    "    name_col = \"행정구역(시군구)별\"\n",
    "\n",
    "    CITY_WARDS = {\n",
    "        # 경기도(41)\n",
    "        \"수원시\":  ( \"41\", [\"장안구\",\"권선구\",\"팔달구\",\"영통구\"] ),\n",
    "        \"성남시\":  ( \"41\", [\"수정구\",\"중원구\",\"분당구\"] ),\n",
    "        \"안양시\":  ( \"41\", [\"만안구\",\"동안구\"] ),\n",
    "        \"고양시\":  ( \"41\", [\"덕양구\",\"일산동구\",\"일산서구\"] ),\n",
    "        \"안산시\":  ( \"41\", [\"상록구\",\"단원구\"] ),\n",
    "        \"용인시\":  ( \"41\", [\"처인구\",\"기흥구\",\"수지구\"] ),\n",
    "        \"부천시\":  ( \"41\", [\"원미구\",\"소사구\",\"오정구\"] ),  # 과거 구\n",
    "        # 충북(43)\n",
    "        \"청주시\":  ( \"43\", [\"상당구\",\"서원구\",\"흥덕구\",\"청원구\"] ),\n",
    "        # 충남(44)\n",
    "        \"천안시\":  ( \"44\", [\"동남구\",\"서북구\"] ),\n",
    "        # 전북(45)\n",
    "        \"전주시\":  ( \"45\", [\"완산구\",\"덕진구\"] ),\n",
    "        \"전주시\":  ( \"52\", [\"완산구\",\"덕진구\"] ),\n",
    "        # 경북(47) — ★ 포항시 남구/북구만 대상\n",
    "        \"포항시\":  ( \"47\", [\"남구\",\"북구\"] ),\n",
    "        # 경남(48)\n",
    "        \"창원시\":  ( \"48\", [\"의창구\",\"성산구\",\"마산합포구\",\"마산회원구\",\"진해구\"] ),\n",
    "    }\n",
    "\n",
    "    METRO_PREFIX = {\"11\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"36\",\"50\"}  # 접지 않음\n",
    "\n",
    "    mapping = {}\n",
    "    for city, (sido_prefix, ward_list) in CITY_WARDS.items():\n",
    "        mask = (\n",
    "            df[code_col].astype(str).str.startswith(sido_prefix) &\n",
    "            df[name_col].astype(str).isin(ward_list)\n",
    "        )\n",
    "        subset = df.loc[mask, [code_col, name_col]].drop_duplicates()\n",
    "        subset = subset[~subset[code_col].astype(str).str[:2].isin(METRO_PREFIX)]\n",
    "        for _, row in subset.iterrows():\n",
    "            sgg_code = str(row[code_col]).strip()\n",
    "            if re.fullmatch(r\"\\d{5}\", sgg_code):\n",
    "                mapping[sgg_code] = city  # 이 5자리 코드는 해당 '시'로 접는다\n",
    "    return mapping\n",
    "\n",
    "GENERAL_WARD_CODE_TO_CITY = build_general_city_ward_code_map(CSV_MONTHLY)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 1) 월별 CSV (2011~)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def load_monthly(csv_path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path, dtype=str, encoding=\"cp949\")\n",
    "    code_col = \"[A]행정구역(시군구)별\"\n",
    "    name_col = \"행정구역(시군구)별\"\n",
    "    itemcode_col  = \"[Item]항목\"\n",
    "    itemlabel_col = \"항목\"\n",
    "\n",
    "    time_cols = [c for c in df.columns if re.match(r\"^20\\d{2}\\.\\d{2}\\s*월$\", str(c))]\n",
    "    time_cols = [c for c in time_cols if not str(c).lower().startswith(\"unnamed\")]\n",
    "\n",
    "    long_m = df.melt(\n",
    "        id_vars=[code_col, name_col, itemcode_col, itemlabel_col],\n",
    "        value_vars=time_cols, var_name=\"time_col\", value_name=\"value\"\n",
    "    )\n",
    "\n",
    "    ym = long_m[\"time_col\"].str.extract(r\"^(?P<year>20\\d{2})\\.(?P<month>\\d{2})\")\n",
    "    long_m[\"year\"]  = ym[\"year\"].astype(\"Int64\")\n",
    "    long_m[\"month\"] = ym[\"month\"].astype(\"Int64\")\n",
    "\n",
    "    long_m[\"value\"] = (long_m[\"value\"].astype(str).str.replace(\",\", \"\", regex=False)\n",
    "                       .replace({\"-\": np.nan, \"\": np.nan}))\n",
    "    long_m[\"value\"] = pd.to_numeric(long_m[\"value\"], errors=\"coerce\")\n",
    "\n",
    "    long_m[\"sgg_code\"] = long_m[code_col].astype(str).str.extract(r\"\\b(\\d{5})\\b\", expand=False)\n",
    "    long_m = long_m[long_m[\"sgg_code\"].str.fullmatch(r\"\\d{5}\", na=False)].copy()\n",
    "\n",
    "    long_m[\"sgg_name\"] = (\n",
    "        long_m[name_col].astype(str)\n",
    "        .str.replace(r\"\\u3000\", \" \", regex=True)\n",
    "        .str.replace(r\"[\\s]*\\(?\\b\\d{5}\\)?\", \"\", regex=True)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "    long_m[\"sido_code\"] = long_m[\"sgg_code\"].str[:2]\n",
    "    long_m[\"sido_name\"] = long_m[\"sido_code\"].map(SIDO_MAP)\n",
    "\n",
    "    def sex_from_itemcode(s):\n",
    "        s = str(s)\n",
    "        if s.startswith(\"T20\"): return \"total\"\n",
    "        if s.startswith(\"T21\"): return \"male\"\n",
    "        if s.startswith(\"T22\"): return \"female\"\n",
    "        return None\n",
    "\n",
    "    long_m[\"sex\"] = long_m[itemcode_col].map(sex_from_itemcode)\n",
    "\n",
    "    monthly_wide = (\n",
    "        long_m.pivot_table(\n",
    "            index=[\"sido_code\",\"sido_name\",\"sgg_code\",\"sgg_name\",\"year\",\"month\"],\n",
    "            columns=\"sex\", values=\"value\", aggfunc=\"first\"\n",
    "        ).reset_index()\n",
    "    )\n",
    "    for c in [\"total\",\"male\",\"female\"]:\n",
    "        if c not in monthly_wide.columns:\n",
    "            monthly_wide[c] = np.nan\n",
    "    return monthly_wide\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 2) 연별 XLSX (2008~2010)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def load_yearly(xlsx_path: Path) -> pd.DataFrame:\n",
    "    raw_y = pd.read_excel(xlsx_path, dtype=str, engine=\"openpyxl\")\n",
    "    meta = raw_y.iloc[0]\n",
    "    df_y = raw_y.iloc[1:].copy()\n",
    "\n",
    "    region_col = next(c for c in df_y.columns if \"행정구역\" in str(c))\n",
    "    df_y[region_col] = df_y[region_col].ffill()\n",
    "\n",
    "    records = []\n",
    "    for col in df_y.columns:\n",
    "        if col == region_col:\n",
    "            continue\n",
    "        m = re.search(r\"(20\\d{2})\", str(col))\n",
    "        if not m:\n",
    "            continue\n",
    "        year = int(m.group(1))\n",
    "        month = 12\n",
    "\n",
    "        label = str(meta.get(col, \"\"))\n",
    "        if   label.startswith(\"T20\"): sex = \"total\"\n",
    "        elif label.startswith(\"T21\"): sex = \"male\"\n",
    "        elif label.startswith(\"T22\"): sex = \"female\"\n",
    "        else:\n",
    "            if str(col).endswith(\".1\"):   sex = \"male\"\n",
    "            elif str(col).endswith(\".2\"): sex = \"female\"\n",
    "            else:                         sex = \"total\"\n",
    "\n",
    "        for _, row in df_y[[region_col, col]].dropna(subset=[col]).iterrows():\n",
    "            region_raw = str(row[region_col])\n",
    "            mcode = re.search(r\"\\b(\\d{5})\\b\", region_raw)\n",
    "            if not mcode:\n",
    "                continue\n",
    "            sgg_code = mcode.group(1)\n",
    "            sgg_name = re.sub(r\"[\\s]*\\(?\\b\\d{5}\\)?\", \"\", region_raw.replace(\"\\u3000\", \" \").strip()).strip()\n",
    "\n",
    "            v = str(row[col]).strip()\n",
    "            if v in {\"\", \"-\"}:\n",
    "                continue\n",
    "            try:\n",
    "                val = float(v.replace(\",\", \"\"))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            records.append({\n",
    "                \"sido_code\": sgg_code[:2],\n",
    "                \"sgg_code\":  sgg_code,\n",
    "                \"sgg_name\":  sgg_name,\n",
    "                \"year\": year,\n",
    "                \"month\": month,\n",
    "                \"sex\": sex,\n",
    "                \"value\": val\n",
    "            })\n",
    "\n",
    "    yearly_long = pd.DataFrame.from_records(records)\n",
    "    yearly_wide = (\n",
    "        yearly_long.pivot_table(\n",
    "            index=[\"sido_code\",\"sgg_code\",\"sgg_name\",\"year\",\"month\"],\n",
    "            columns=\"sex\", values=\"value\", aggfunc=\"first\"\n",
    "        ).reset_index()\n",
    "    )\n",
    "    yearly_wide[\"sido_name\"] = yearly_wide[\"sido_code\"].map(SIDO_MAP)\n",
    "    return yearly_wide\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 3) 패널 결합(연+월)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def build_panel() -> pd.DataFrame:\n",
    "    monthly_wide = load_monthly(CSV_MONTHLY)\n",
    "    yearly_wide  = load_yearly(XLSX_YEARLY)\n",
    "    panel = pd.concat([yearly_wide, monthly_wide], ignore_index=True, sort=False)\n",
    "    panel[\"year\"]  = pd.to_numeric(panel[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    panel[\"month\"] = pd.to_numeric(panel[\"month\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    for c in [\"total\",\"male\",\"female\"]:\n",
    "        if c not in panel.columns:\n",
    "            panel[c] = np.nan\n",
    "    panel.loc[panel[\"sido_code\"]==\"51\", \"sido_name\"] = \"강원특별자치도\"\n",
    "    panel.loc[panel[\"sido_code\"]==\"52\", \"sido_name\"] = \"전북특별자치도\"\n",
    "    panel = panel.sort_values([\"sido_code\",\"sgg_code\",\"year\",\"month\"]).reset_index(drop=True)\n",
    "    return panel\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 4) 집계 규칙 (분리 저장용)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "SPECIAL_MARKERS = (\"특별시\",\"광역시\",\"특별자치시\")\n",
    "CITY_GU_PAT     = re.compile(r\"^(?P<city>.+?시)\\s+(?P<gu>.+?구)$\")\n",
    "\n",
    "def is_metro_or_special(sido_name: str, sgg_name: str) -> bool:\n",
    "    s1 = str(sido_name) if pd.notna(sido_name) else \"\"\n",
    "    s2 = str(sgg_name)  if pd.notna(sgg_name)  else \"\"\n",
    "    return any(mk in s1 for mk in SPECIAL_MARKERS) or any(mk in s2 for mk in SPECIAL_MARKERS)\n",
    "\n",
    "def collapsed_sigungu_for_output(sido_name: str, sgg_name: str, sgg_code: str) -> str:\n",
    "    \"\"\"\n",
    "    반환 sigungu:\n",
    "      - 메트로(특별/광역/특별자치시): '구/군'만 (예: '종로구', '남구')\n",
    "      - 일반시의 구(접기 대상 코드): '시' (예: '포항시', '용인시')\n",
    "      - '시 구' 패턴이면 '시'\n",
    "      - 그 외: 원본 sgg_name\n",
    "    \"\"\"\n",
    "    sgg_name = \"\" if pd.isna(sgg_name) else str(sgg_name)\n",
    "    if is_metro_or_special(sido_name, sgg_name):\n",
    "        m = CITY_GU_PAT.match(sgg_name)\n",
    "        return m.group(\"gu\") if m else sgg_name  # 안전하게 '구'만 남김\n",
    "\n",
    "    if sgg_code in GENERAL_WARD_CODE_TO_CITY:\n",
    "        return GENERAL_WARD_CODE_TO_CITY[sgg_code]  # 부모 '시'명\n",
    "\n",
    "    m = CITY_GU_PAT.match(sgg_name)\n",
    "    if m:  # 일반시 '시 구' → '시'\n",
    "        return m.group(\"city\")\n",
    "\n",
    "    return sgg_name  # 군/시 단독 등\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 5) 실행\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def main():\n",
    "    panel = build_panel()\n",
    "    panel.to_csv(OUT_PANEL, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # 출력용 분리 컬럼 생성\n",
    "    panel[\"_sido_out\"] = panel[\"sido_name\"]\n",
    "    panel[\"_sigg_out\"] = [\n",
    "        collapsed_sigungu_for_output(panel.at[i,\"sido_name\"], panel.at[i,\"sgg_name\"], str(panel.at[i,\"sgg_code\"]))\n",
    "        for i in panel.index\n",
    "    ]\n",
    "\n",
    "    agg_cols = [\"total\",\"male\",\"female\"]\n",
    "    out = (\n",
    "        panel.groupby([\"_sido_out\",\"_sigg_out\",\"year\",\"month\"], dropna=False, as_index=False)[agg_cols]\n",
    "              .sum(min_count=1)\n",
    "              .rename(columns={\"_sido_out\":\"sido_name\", \"_sigg_out\":\"sigungu\"})\n",
    "              .sort_values([\"sido_name\",\"sigungu\",\"year\",\"month\"])\n",
    "              .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    out[\"yyyymm\"] = (out[\"year\"].astype(int) * 100 + out[\"month\"].astype(int)).astype(int)\n",
    "    out.to_csv(OUT_AGG, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"[OK] population_panel.csv saved: {OUT_PANEL}\")\n",
    "    print(f\"[OK] population_panel_sgg_aggregated.csv saved: {OUT_AGG}\")\n",
    "    print(f\"rows={len(out):,}, cols={list(out.columns)}\")\n",
    "    # 빠른 확인: 포항 남/북구가 '경상북도-포항시'로 접혔는지\n",
    "    check = panel[panel[\"sgg_code\"].isin([\"47111\",\"47113\"])]\n",
    "    if not check.empty:\n",
    "        lbl = out[(out[\"sido_name\"]==\"경상북도\") & (out[\"sigungu\"]==\"포항시\")].head(1)\n",
    "        print(\"[DEBUG] 포항시 예시:\", lbl.to_dict(orient=\"records\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cbf154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5be5b83a",
   "metadata": {},
   "source": [
    "### SIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67a285cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 2009_상반기_지역_20251110_33046.csv (연도=2009, 반기=상반기)\n",
      "Processing: 2009_하반기_지역_20251110_50224.csv (연도=2009, 반기=하반기)\n",
      "Processing: 2010_상반기_지역_20251110_33046.csv (연도=2010, 반기=상반기)\n",
      "Processing: 2010_하반기_지역_20251110_50224.csv (연도=2010, 반기=하반기)\n",
      "Processing: 2011_상반기_지역_20251110_13148.csv (연도=2011, 반기=상반기)\n",
      "Processing: 2011_하반기_지역_20251110_10247.csv (연도=2011, 반기=하반기)\n",
      "Processing: 2012_상반기_지역_20251110_13148.csv (연도=2012, 반기=상반기)\n",
      "Processing: 2012_하반기_지역_20251110_10247.csv (연도=2012, 반기=하반기)\n",
      "Processing: 2013_상반기_지역_20251110_13148.csv (연도=2013, 반기=상반기)\n",
      "Processing: 2013_하반기_지역_20251110_10247.csv (연도=2013, 반기=하반기)\n",
      "Processing: 2014_상반기_지역_20251110_13148.csv (연도=2014, 반기=상반기)\n",
      "Processing: 2014_하반기_지역_20251110_10247.csv (연도=2014, 반기=하반기)\n",
      "Processing: 2015_상반기_지역_20251110_13148.csv (연도=2015, 반기=상반기)\n",
      "Processing: 2015_하반기_지역_20251110_10247.csv (연도=2015, 반기=하반기)\n",
      "Processing: 2016_상반기_지역_20251110_47738.csv (연도=2016, 반기=상반기)\n",
      "Processing: 2016_하반기_지역_20251110_82571.csv (연도=2016, 반기=하반기)\n",
      "Processing: 2017_상반기_지역_20251110_47738.csv (연도=2017, 반기=상반기)\n",
      "Processing: 2017_하반기_지역_20251110_82571.csv (연도=2017, 반기=하반기)\n",
      "Processing: 2018_상반기_지역_20251110_47738.csv (연도=2018, 반기=상반기)\n",
      "Processing: 2018_하반기_지역_20251110_82571.csv (연도=2018, 반기=하반기)\n",
      "Processing: 2019_상반기_지역_20251110_47738.csv (연도=2019, 반기=상반기)\n",
      "Processing: 2019_하반기_지역_20251110_82571.csv (연도=2019, 반기=하반기)\n",
      "Processing: 2020_상반기_지역_20251110_47738.csv (연도=2020, 반기=상반기)\n",
      "Processing: 2020_하반기_지역_20251110_82571.csv (연도=2020, 반기=하반기)\n",
      "Processing: 2021_상반기_지역_20251110_94268.csv (연도=2021, 반기=상반기)\n",
      "Processing: 2021_하반기_지역_20251110_61383.csv (연도=2021, 반기=하반기)\n",
      "Processing: 2022_상반기_지역_20251110_94268.csv (연도=2022, 반기=상반기)\n",
      "Processing: 2022_하반기_지역_20251110_61383.csv (연도=2022, 반기=하반기)\n",
      "Processing: 2023_상반기_지역_20251110_94268.csv (연도=2023, 반기=상반기)\n",
      "Processing: 2023_하반기_지역_20251110_61383.csv (연도=2023, 반기=하반기)\n",
      "Processing: 2024_상반기_지역_20251110_94268.csv (연도=2024, 반기=상반기)\n",
      "Processing: 2024_하반기_지역_20251110_61383.csv (연도=2024, 반기=하반기)\n",
      "Processing: 2025_상반기_지역_20251110_94268.csv (연도=2025, 반기=상반기)\n",
      "완료! 결과 저장 위치: /Users/kjh/Documents/geostat3_e9/MDIS_panel.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import unicodedata as ud\n",
    "import re\n",
    "\n",
    "# 1) CSV들이 들어 있는 폴더 경로로 수정하세요\n",
    "BASE_DIR = Path(\"/Users/kjh/Documents/geostat3_e9/data/MDIS\")\n",
    "\n",
    "# 예: 2009_상반기_지역_20251110_33046.csv / 2010_하반기_지역_20251110_XXXXX.csv\n",
    "PATTERN = \"*20251110_*.csv\"\n",
    "\n",
    "# 2) 헬퍼들 --------------------------------------------------------------\n",
    "def pick_first_existing(columns, candidates):\n",
    "    \"\"\"candidates 중 실제 존재하는 첫 컬럼명 반환\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in columns:\n",
    "            return c\n",
    "    raise KeyError(f\"None of {candidates} found in columns: {list(columns)}\")\n",
    "\n",
    "def parse_year_half(path: Path):\n",
    "    \"\"\"파일명에서 연도/반기 추출\"\"\"\n",
    "    stem = path.stem\n",
    "    parts = stem.split(\"_\")\n",
    "    year = int(re.match(r\"\\d{4}\", parts[0]).group(0))\n",
    "    half_raw = parts[1]                  # '상반기' or '하반기'\n",
    "    half = ud.normalize(\"NFC\", half_raw)\n",
    "    return year, half\n",
    "\n",
    "# 조사항목 코드 → 열 이름 매핑\n",
    "ITEM_MAP = {\n",
    "    \"A\": \"구인인원\",\n",
    "    \"B\": \"채용인원\",\n",
    "    \"C\": \"미충원인원\",\n",
    "    \"D\": \"현원\",\n",
    "    \"E\": \"부족인원\",\n",
    "    \"F\": \"채용계획인원\",\n",
    "}\n",
    "\n",
    "frames = []\n",
    "\n",
    "# 3) 파일 루프 -----------------------------------------------------------\n",
    "for csv_path in sorted(BASE_DIR.glob(PATTERN)):\n",
    "    year, half = parse_year_half(csv_path)\n",
    "\n",
    "    # 2009~2025년만\n",
    "    if not (2009 <= year <= 2025):\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing: {csv_path.name} (연도={year}, 반기={half})\")\n",
    "\n",
    "    df = pd.read_csv(csv_path, encoding=\"cp949\")\n",
    "\n",
    "    # 컬럼 자동 매핑\n",
    "    industry_col = pick_first_existing(df.columns, [\"산업대분류\", \"산업대분류코드\"])\n",
    "    region_col   = pick_first_existing(df.columns, [\"지역분류\", \"지역구분코드\"])\n",
    "    weight_col   = pick_first_existing(df.columns, [\"가중값\", \"가중치\"])\n",
    "    count_col    = pick_first_existing(df.columns, [\"인원\", \"인원수\"])\n",
    "    item_col     = pick_first_existing(df.columns, [\"조사항목\", \"조사항목코드\"])\n",
    "\n",
    "    # 산업대분류 C만\n",
    "    df = df[df[industry_col] == \"C\"].copy()\n",
    "\n",
    "    # 컬럼명 통일\n",
    "    df = df.rename(columns={region_col: \"지역코드\", item_col: \"조사항목코드\"})\n",
    "\n",
    "    # 연도/반기, 가중인원\n",
    "    df[\"연도\"] = year\n",
    "    df[\"반기\"] = half\n",
    "    df[\"가중인원\"] = df[count_col] * df[weight_col]\n",
    "\n",
    "    frames.append(df)\n",
    "\n",
    "if not frames:\n",
    "    raise RuntimeError(\"조건(2009~2025, 산업 C)에 맞는 데이터가 없습니다.\")\n",
    "\n",
    "big_df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# 4) 연도 × 반기 × 지역 × 조사항목코드별 합계 (long)\n",
    "long = (\n",
    "    big_df\n",
    "    .groupby([\"연도\", \"반기\", \"지역코드\", \"조사항목코드\"], as_index=False)[\"가중인원\"]\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "# 코드 → 한글 항목명으로 변환\n",
    "long[\"조사항목명\"] = long[\"조사항목코드\"].map(ITEM_MAP)\n",
    "\n",
    "# 5) wide 형태로 pivot: 항목명이 컬럼이 되도록\n",
    "wide = (\n",
    "    long\n",
    "    .pivot_table(\n",
    "        index=[\"연도\", \"반기\", \"지역코드\"],\n",
    "        columns=\"조사항목명\",\n",
    "        values=\"가중인원\",\n",
    "        aggfunc=\"sum\"\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 컬럼 이름 정리\n",
    "wide.columns.name = None\n",
    "\n",
    "# 열 순서 정리 (있다면 그 순서로)\n",
    "col_order = [\"연도\", \"반기\", \"지역코드\",\n",
    "             \"구인인원\", \"채용인원\", \"미충원인원\",\n",
    "             \"현원\", \"부족인원\", \"채용계획인원\"]\n",
    "wide = wide[[c for c in col_order if c in wide.columns]]\n",
    "\n",
    "# 결과 저장\n",
    "out_path = \"/Users/kjh/Documents/geostat3_e9/MDIS_panel.csv\"\n",
    "wide.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"완료! 결과 저장 위치:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee52e8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snustdatasci-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
