{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f6ea9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kjh/Documents/geostat3_e9'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23751bd0",
   "metadata": {},
   "source": [
    "## Find Unique $(i, t)$ Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4df46b6",
   "metadata": {},
   "source": [
    "### E9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "632a4d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sido</th>\n",
       "      <th>sigungu</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강원도</td>\n",
       "      <td>강릉시</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>강원도</td>\n",
       "      <td>강릉시</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>강원도</td>\n",
       "      <td>강릉시</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>강원도</td>\n",
       "      <td>강릉시</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>강원도</td>\n",
       "      <td>강릉시</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sido sigungu  year\n",
       "0  강원도     강릉시  2009\n",
       "1  강원도     강릉시  2010\n",
       "2  강원도     강릉시  2011\n",
       "3  강원도     강릉시  2012\n",
       "4  강원도     강릉시  2013"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 파일 경로\n",
    "path = Path(\"/Users/kjh/Documents/geostat3_e9/E9_panel_sgg_aggregated.csv\")  # 필요시 교체\n",
    "\n",
    "# 1) 데이터 로드\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# 2) 컬럼명 소문자/공백 정리\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# 3) 후보 컬럼 자동 매핑\n",
    "ALIAS = {\n",
    "    \"sido\":    [\"sido\", \"시도\", \"광역시도\", \"province\", \"sido_nm\", \"sido_name\", \"sido_name_kor\"],\n",
    "    \"sigungu\": [\"sigungu\", \"시군구\", \"sgg\", \"시군구명\", \"sigungu_nm\", \"sigungu_name\"],\n",
    "    \"year\":    [\"year\", \"연도\", \"yyyy\"],\n",
    "    \"date\":    [\"date\", \"날짜\", \"ym\", \"yyyymm\", \"연월\"]\n",
    "}\n",
    "\n",
    "def pick(col_aliases):\n",
    "    for c in col_aliases:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "sido_col    = pick(ALIAS[\"sido\"])\n",
    "sigungu_col = pick(ALIAS[\"sigungu\"])\n",
    "year_col    = pick(ALIAS[\"year\"])\n",
    "date_col    = pick(ALIAS[\"date\"])  # 연도 파생용(없으면 None)\n",
    "\n",
    "if sido_col is None or sigungu_col is None:\n",
    "    raise KeyError(\"시도/시군구 컬럼을 찾지 못했습니다. 컬럼명을 확인해주세요.\")\n",
    "\n",
    "# 4) year 파생 (year가 없고 date/yyyymm만 있을 때)\n",
    "if year_col is None:\n",
    "    if date_col is None:\n",
    "        raise KeyError(\"연도(year) 또는 연월(date/yyyymm) 관련 컬럼을 찾지 못했습니다.\")\n",
    "    # 문자열 변환 후 앞 4자리로 연도 추출\n",
    "    year_series = pd.to_datetime(\n",
    "        df[date_col].astype(str).str.replace(r\"[^0-9]\", \"\", regex=True).str[:6],  # 202001 같은 형태 유도\n",
    "        format=\"%Y%m\", errors=\"coerce\"\n",
    "    ).dt.year\n",
    "else:\n",
    "    # 숫자/문자 혼재 대비하여 깔끔한 연도로 정규화\n",
    "    year_series = pd.to_numeric(df[year_col], errors=\"coerce\")\n",
    "    if year_series.isna().all() and date_col is not None:\n",
    "        year_series = pd.to_datetime(\n",
    "            df[date_col].astype(str).str.replace(r\"[^0-9]\", \"\", regex=True).str[:6],\n",
    "            format=\"%Y%m\", errors=\"coerce\"\n",
    "        ).dt.year\n",
    "\n",
    "if year_series.isna().any():\n",
    "    # 불가피할 때만 남김. 필요시 dropna()로 제거 가능\n",
    "    pass\n",
    "\n",
    "# 5) 유일 조합 테이블 생성\n",
    "uniq = (\n",
    "    pd.DataFrame({\n",
    "        \"sido\": df[sido_col].astype(str).str.strip(),\n",
    "        \"sigungu\": df[sigungu_col].astype(str).str.strip(),\n",
    "        \"year\": year_series.astype(\"Int64\")  # 결측 허용 정수\n",
    "    })\n",
    "    .dropna(subset=[\"sido\", \"sigungu\", \"year\"])\n",
    "    .drop_duplicates()\n",
    "    .sort_values([\"sido\", \"sigungu\", \"year\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 6) 저장(선택)\n",
    "uniq.to_csv(\"unique_e9.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "uniq.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c2d211",
   "metadata": {},
   "source": [
    "### Trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1bdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sido</th>\n",
       "      <th>sigungu</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강원특별자치도</td>\n",
       "      <td>강릉시</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>강원특별자치도</td>\n",
       "      <td>강릉시</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>강원특별자치도</td>\n",
       "      <td>강릉시</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>강원특별자치도</td>\n",
       "      <td>강릉시</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>강원특별자치도</td>\n",
       "      <td>강릉시</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sido sigungu  year\n",
       "0  강원특별자치도     강릉시  2008\n",
       "1  강원특별자치도     강릉시  2009\n",
       "2  강원특별자치도     강릉시  2010\n",
       "3  강원특별자치도     강릉시  2011\n",
       "4  강원특별자치도     강릉시  2012"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 파일 경로\n",
    "path = Path(\"/Users/kjh/Documents/geostat3_e9/trade_panel.csv\")\n",
    "\n",
    "# 1) 데이터 로드\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# 2) 컬럼명 소문자/공백 정리\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# 3) 후보 컬럼 자동 매핑\n",
    "ALIAS = {\n",
    "    \"sido\":    [\"sido\", \"시도\", \"광역시도\", \"province\", \"sido_nm\", \"sido_name\", \"sido_name_kor\"],\n",
    "    \"sigungu\": [\"sigungu\", \"시군구\", \"sgg\", \"시군구명\", \"sigungu_nm\", \"sigungu_name\"],\n",
    "    \"region\":  [\"region\", \"지역\", \"행정구역\", \"행정구역명\", \"시도_시군구\"],\n",
    "    \"year\":    [\"year\", \"연도\", \"yyyy\"],\n",
    "    \"date\":    [\"date\", \"날짜\", \"ym\", \"yyyymm\", \"연월\"]\n",
    "}\n",
    "\n",
    "def pick(cols, in_df):\n",
    "    for c in cols:\n",
    "        if c in in_df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "sido_col    = pick(ALIAS[\"sido\"], df)\n",
    "sigungu_col = pick(ALIAS[\"sigungu\"], df)\n",
    "region_col  = pick(ALIAS[\"region\"], df)\n",
    "year_col    = pick(ALIAS[\"year\"], df)\n",
    "date_col    = pick(ALIAS[\"date\"], df)\n",
    "\n",
    "# ---------- (A) region -> (sido, sigungu) 분리 ----------\n",
    "# 공식/변경 포함 시도명 후보(긴 것 먼저 매칭)\n",
    "SIDO_NAMES = [\n",
    "    \"세종특별자치시\", \"제주특별자치도\", \"강원특별자치도\", \"전북특별자치도\",\n",
    "    \"서울특별시\", \"부산광역시\", \"대구광역시\", \"인천광역시\", \"광주광역시\", \"대전광역시\", \"울산광역시\",\n",
    "    \"경기도\", \"강원도\", \"충청북도\", \"충청남도\", \"전라북도\", \"전라남도\", \"경상북도\", \"경상남도\"\n",
    "]\n",
    "# 영문/축약 대응(있다면)\n",
    "SIDO_EN_MAP = {\n",
    "    \"seoul\": \"서울특별시\", \"busan\": \"부산광역시\", \"daegu\": \"대구광역시\", \"incheon\": \"인천광역시\",\n",
    "    \"gwangju\": \"광주광역시\", \"daejeon\": \"대전광역시\", \"ulsan\": \"울산광역시\", \"sejong\": \"세종특별자치시\",\n",
    "    \"gyeonggi\": \"경기도\", \"gangwon\": \"강원특별자치도\", \"chungbuk\": \"충청북도\", \"chungnam\": \"충청남도\",\n",
    "    \"jeonbuk\": \"전북특별자치도\", \"jeonnam\": \"전라남도\", \"gyeongbuk\": \"경상북도\", \"gyeongnam\": \"경상남도\",\n",
    "    \"jeju\": \"제주특별자치도\"\n",
    "}\n",
    "\n",
    "def clean_region(s):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    s = str(s)\n",
    "    s = re.sub(r\"[\\(\\[\\{].*?[\\)\\]\\}]\", \"\", s)  # 괄호 내용 제거\n",
    "    s = s.replace(\"/\", \" \").replace(\"-\", \" \").replace(\",\", \" \")\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def split_region(s):\n",
    "    \"\"\" region 문자열에서 (시도, 시군구) 추출 \"\"\"\n",
    "    if not s:\n",
    "        return (None, None)\n",
    "    raw = clean_region(s)\n",
    "\n",
    "    # 1) 쉼표/슬래시로 이미 구분된 케이스 처리 후 재시도\n",
    "    for sep in [\",\", \"/\", \"-\"]:\n",
    "        if sep in str(s):\n",
    "            parts = [p.strip() for p in str(s).split(sep)]\n",
    "            if len(parts) >= 2:\n",
    "                return split_region(\" \".join(parts))  # 공백 기반 재처리\n",
    "\n",
    "    # 2) 시도명 prefix 매칭(가장 긴 시도명 우선)\n",
    "    for sido_name in sorted(SIDO_NAMES, key=len, reverse=True):\n",
    "        if raw.startswith(sido_name):\n",
    "            rest = raw[len(sido_name):].strip()\n",
    "            return (sido_name, rest if rest else None)\n",
    "\n",
    "    # 3) 영문/로마자 시도명 시작하는 경우\n",
    "    first_tok = raw.split(\" \")[0].lower()\n",
    "    if first_tok in SIDO_EN_MAP:\n",
    "        sido_name = SIDO_EN_MAP[first_tok]\n",
    "        rest = raw[len(first_tok):].strip()\n",
    "        # 영문 토큰 제거를 위해 첫 토큰 제외\n",
    "        rest = \" \".join(raw.split(\" \")[1:]).strip() or None\n",
    "        return (sido_name, rest)\n",
    "\n",
    "    # 4) fallback: 첫 토큰을 시도, 나머지를 시군구로\n",
    "    toks = raw.split(\" \")\n",
    "    if len(toks) == 1:\n",
    "        return (toks[0], None)\n",
    "    return (toks[0], \" \".join(toks[1:]))\n",
    "\n",
    "# region이 있고(또는 시도/시군구 중 하나라도 없으면) region에서 파생\n",
    "if region_col is not None and (sido_col is None or sigungu_col is None):\n",
    "    tmp = df[region_col].map(clean_region)\n",
    "    parsed = tmp.map(split_region)\n",
    "    df[\"_sido_from_region\"]    = parsed.map(lambda x: x[0])\n",
    "    df[\"_sigungu_from_region\"] = parsed.map(lambda x: x[1])\n",
    "    # 우선순위: 기존 컬럼 > region 파생\n",
    "    if sido_col is None:\n",
    "        sido_col = \"_sido_from_region\"\n",
    "    if sigungu_col is None:\n",
    "        sigungu_col = \"_sigungu_from_region\"\n",
    "\n",
    "# 최종 체크\n",
    "if sido_col is None or sigungu_col is None:\n",
    "    raise KeyError(\"시도/시군구 컬럼을 찾지 못했습니다. (region 분해 실패 가능)\")\n",
    "\n",
    "# ---------- (B) 연도 파생 ----------\n",
    "if year_col is None:\n",
    "    if date_col is None:\n",
    "        raise KeyError(\"연도(year) 또는 연월(date/yyyymm) 관련 컬럼을 찾지 못했습니다.\")\n",
    "    year_series = pd.to_datetime(\n",
    "        df[date_col].astype(str).str.replace(r\"[^0-9]\", \"\", regex=True).str[:6],\n",
    "        format=\"%Y%m\", errors=\"coerce\"\n",
    "    ).dt.year\n",
    "else:\n",
    "    year_series = pd.to_numeric(df[year_col], errors=\"coerce\")\n",
    "    if year_series.isna().all() and date_col is not None:\n",
    "        year_series = pd.to_datetime(\n",
    "            df[date_col].astype(str).str.replace(r\"[^0-9]\", \"\", regex=True).str[:6],\n",
    "            format=\"%Y%m\", errors=\"coerce\"\n",
    "        ).dt.year\n",
    "\n",
    "# ---------- (C) 유일 조합 테이블 ----------\n",
    "uniq = (\n",
    "    pd.DataFrame({\n",
    "        \"sido\": df[sido_col].astype(str).str.strip(),\n",
    "        \"sigungu\": df[sigungu_col].astype(str).str.strip(),\n",
    "        \"year\": year_series.astype(\"Int64\")\n",
    "    })\n",
    "    .dropna(subset=[\"sido\", \"year\"])  # sigungu가 없는 행은 남기고 싶으면 여기서 제외하지 말 것\n",
    "    .assign(sigungu=lambda x: x[\"sigungu\"].replace({\"\": pd.NA}))\n",
    "    .drop_duplicates()\n",
    "    .sort_values([\"sido\", \"sigungu\", \"year\"], na_position=\"last\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 저장\n",
    "uniq.to_csv(\"unique_trade.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "uniq.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5ee02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sido</th>\n",
       "      <th>sigungu</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강원도</td>\n",
       "      <td>None</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>강원도</td>\n",
       "      <td>None</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>강원도</td>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>강원도</td>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>강원도</td>\n",
       "      <td>None</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sido sigungu  year\n",
       "0  강원도    None  2008\n",
       "1  강원도    None  2009\n",
       "2  강원도    None  2010\n",
       "3  강원도    None  2011\n",
       "4  강원도    None  2012"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import re\n",
    "# import pandas as pd\n",
    "# from pathlib import Path\n",
    "\n",
    "# # 파일 경로\n",
    "# path = Path(\"/Users/kjh/Documents/geostat3_e9/manufacturing_production_index.csv\")\n",
    "\n",
    "# # 1) 데이터 로드\n",
    "# df = pd.read_csv(path)\n",
    "\n",
    "# # 2) 컬럼명 소문자/공백 정리\n",
    "# df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# # 3) 후보 컬럼 자동 매핑\n",
    "# ALIAS = {\n",
    "#     \"sido\":    [\"sido\", \"시도\", \"광역시도\", \"province\", \"sido_nm\", \"sido_name\", \"sido_name_kor\"],\n",
    "#     \"sigungu\": [\"sigungu\", \"시군구\", \"sgg\", \"시군구명\", \"sigungu_nm\", \"sigungu_name\"],\n",
    "#     \"region\":  [\"region\", \"지역\", \"행정구역\", \"행정구역명\", \"시도_시군구\"],\n",
    "#     \"year\":    [\"year\", \"연도\", \"yyyy\"],\n",
    "#     \"date\":    [\"date\", \"날짜\", \"ym\", \"yyyymm\", \"연월\"]\n",
    "# }\n",
    "\n",
    "# def pick(cols, in_df):\n",
    "#     for c in cols:\n",
    "#         if c in in_df.columns:\n",
    "#             return c\n",
    "#     return None\n",
    "\n",
    "# sido_col    = pick(ALIAS[\"sido\"], df)\n",
    "# sigungu_col = pick(ALIAS[\"sigungu\"], df)\n",
    "# region_col  = pick(ALIAS[\"region\"], df)\n",
    "# year_col    = pick(ALIAS[\"year\"], df)\n",
    "# date_col    = pick(ALIAS[\"date\"], df)\n",
    "\n",
    "# # ---------- (A) region -> (sido, sigungu) 분리 ----------\n",
    "# # 공식/변경 포함 시도명 후보(긴 것 먼저 매칭)\n",
    "# SIDO_NAMES = [\n",
    "#     \"세종특별자치시\", \"제주특별자치도\", \"강원특별자치도\", \"전북특별자치도\",\n",
    "#     \"서울특별시\", \"부산광역시\", \"대구광역시\", \"인천광역시\", \"광주광역시\", \"대전광역시\", \"울산광역시\",\n",
    "#     \"경기도\", \"강원도\", \"충청북도\", \"충청남도\", \"전라북도\", \"전라남도\", \"경상북도\", \"경상남도\"\n",
    "# ]\n",
    "# # 영문/축약 대응(있다면)\n",
    "# SIDO_EN_MAP = {\n",
    "#     \"seoul\": \"서울특별시\", \"busan\": \"부산광역시\", \"daegu\": \"대구광역시\", \"incheon\": \"인천광역시\",\n",
    "#     \"gwangju\": \"광주광역시\", \"daejeon\": \"대전광역시\", \"ulsan\": \"울산광역시\", \"sejong\": \"세종특별자치시\",\n",
    "#     \"gyeonggi\": \"경기도\", \"gangwon\": \"강원특별자치도\", \"chungbuk\": \"충청북도\", \"chungnam\": \"충청남도\",\n",
    "#     \"jeonbuk\": \"전북특별자치도\", \"jeonnam\": \"전라남도\", \"gyeongbuk\": \"경상북도\", \"gyeongnam\": \"경상남도\",\n",
    "#     \"jeju\": \"제주특별자치도\"\n",
    "# }\n",
    "\n",
    "# def clean_region(s):\n",
    "#     if pd.isna(s):\n",
    "#         return None\n",
    "#     s = str(s)\n",
    "#     s = re.sub(r\"[\\(\\[\\{].*?[\\)\\]\\}]\", \"\", s)  # 괄호 내용 제거\n",
    "#     s = s.replace(\"/\", \" \").replace(\"-\", \" \").replace(\",\", \" \")\n",
    "#     s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "#     return s\n",
    "\n",
    "# def split_region(s):\n",
    "#     \"\"\" region 문자열에서 (시도, 시군구) 추출 \"\"\"\n",
    "#     if not s:\n",
    "#         return (None, None)\n",
    "#     raw = clean_region(s)\n",
    "\n",
    "#     # 1) 쉼표/슬래시로 이미 구분된 케이스 처리 후 재시도\n",
    "#     for sep in [\",\", \"/\", \"-\"]:\n",
    "#         if sep in str(s):\n",
    "#             parts = [p.strip() for p in str(s).split(sep)]\n",
    "#             if len(parts) >= 2:\n",
    "#                 return split_region(\" \".join(parts))  # 공백 기반 재처리\n",
    "\n",
    "#     # 2) 시도명 prefix 매칭(가장 긴 시도명 우선)\n",
    "#     for sido_name in sorted(SIDO_NAMES, key=len, reverse=True):\n",
    "#         if raw.startswith(sido_name):\n",
    "#             rest = raw[len(sido_name):].strip()\n",
    "#             return (sido_name, rest if rest else None)\n",
    "\n",
    "#     # 3) 영문/로마자 시도명 시작하는 경우\n",
    "#     first_tok = raw.split(\" \")[0].lower()\n",
    "#     if first_tok in SIDO_EN_MAP:\n",
    "#         sido_name = SIDO_EN_MAP[first_tok]\n",
    "#         rest = raw[len(first_tok):].strip()\n",
    "#         # 영문 토큰 제거를 위해 첫 토큰 제외\n",
    "#         rest = \" \".join(raw.split(\" \")[1:]).strip() or None\n",
    "#         return (sido_name, rest)\n",
    "\n",
    "#     # 4) fallback: 첫 토큰을 시도, 나머지를 시군구로\n",
    "#     toks = raw.split(\" \")\n",
    "#     if len(toks) == 1:\n",
    "#         return (toks[0], None)\n",
    "#     return (toks[0], \" \".join(toks[1:]))\n",
    "\n",
    "# # region이 있고(또는 시도/시군구 중 하나라도 없으면) region에서 파생\n",
    "# if region_col is not None and (sido_col is None or sigungu_col is None):\n",
    "#     tmp = df[region_col].map(clean_region)\n",
    "#     parsed = tmp.map(split_region)\n",
    "#     df[\"_sido_from_region\"]    = parsed.map(lambda x: x[0])\n",
    "#     df[\"_sigungu_from_region\"] = parsed.map(lambda x: x[1])\n",
    "#     # 우선순위: 기존 컬럼 > region 파생\n",
    "#     if sido_col is None:\n",
    "#         sido_col = \"_sido_from_region\"\n",
    "#     if sigungu_col is None:\n",
    "#         sigungu_col = \"_sigungu_from_region\"\n",
    "\n",
    "# # 최종 체크\n",
    "# if sido_col is None or sigungu_col is None:\n",
    "#     raise KeyError(\"시도/시군구 컬럼을 찾지 못했습니다. (region 분해 실패 가능)\")\n",
    "\n",
    "# # ---------- (B) 연도 파생 ----------\n",
    "# if year_col is None:\n",
    "#     if date_col is None:\n",
    "#         raise KeyError(\"연도(year) 또는 연월(date/yyyymm) 관련 컬럼을 찾지 못했습니다.\")\n",
    "#     year_series = pd.to_datetime(\n",
    "#         df[date_col].astype(str).str.replace(r\"[^0-9]\", \"\", regex=True).str[:6],\n",
    "#         format=\"%Y%m\", errors=\"coerce\"\n",
    "#     ).dt.year\n",
    "# else:\n",
    "#     year_series = pd.to_numeric(df[year_col], errors=\"coerce\")\n",
    "#     if year_series.isna().all() and date_col is not None:\n",
    "#         year_series = pd.to_datetime(\n",
    "#             df[date_col].astype(str).str.replace(r\"[^0-9]\", \"\", regex=True).str[:6],\n",
    "#             format=\"%Y%m\", errors=\"coerce\"\n",
    "#         ).dt.year\n",
    "\n",
    "# # ---------- (C) 유일 조합 테이블 ----------\n",
    "# uniq = (\n",
    "#     pd.DataFrame({\n",
    "#         \"sido\": df[sido_col].astype(str).str.strip(),\n",
    "#         \"sigungu\": df[sigungu_col].astype(str).str.strip(),\n",
    "#         \"year\": year_series.astype(\"Int64\")\n",
    "#     })\n",
    "#     .dropna(subset=[\"sido\", \"year\"])  # sigungu가 없는 행은 남기고 싶으면 여기서 제외하지 말 것\n",
    "#     .assign(sigungu=lambda x: x[\"sigungu\"].replace({\"\": pd.NA}))\n",
    "#     .drop_duplicates()\n",
    "#     .sort_values([\"sido\", \"sigungu\", \"year\"], na_position=\"last\")\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "\n",
    "# # 저장\n",
    "# uniq.to_csv(\"unique_manufacturing.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# uniq.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd298199",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d69031d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] unique_pop.csv saved: unique_pop.csv  rows=4,211\n",
      "      sido sigungu  year\n",
      "0  강원특별자치도     강릉시  2008\n",
      "1  강원특별자치도     강릉시  2009\n",
      "2  강원특별자치도     강릉시  2010\n",
      "3  강원특별자치도     강릉시  2011\n",
      "4  강원특별자치도     강릉시  2012\n",
      "5  강원특별자치도     강릉시  2013\n",
      "6  강원특별자치도     강릉시  2014\n",
      "7  강원특별자치도     강릉시  2015\n",
      "8  강원특별자치도     강릉시  2016\n",
      "9  강원특별자치도     강릉시  2017\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "unique_pop 생성 (검증된 컬럼명 사용)\n",
    "- 입력 : /Users/kjh/Documents/geostat3_e9/population_panel_sgg_aggregated.csv\n",
    "- 출력 : unique_pop.csv  (컬럼: sido, sigungu, year)\n",
    "- 비고 : 광역·특별(자치)시는 '시도명 + 구/군' 형태가 이미 들어 있으므로\n",
    "        남구/서구/중구 등의 중복 문제 없이 안전.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 경로 설정 (필요시 수정)\n",
    "IN_PATH  = Path(\"/Users/kjh/Documents/geostat3_e9/population_panel_sgg_aggregated.csv\")\n",
    "OUT_PATH = Path(\"unique_pop.csv\")  # 현재 작업 디렉토리에 저장\n",
    "\n",
    "# 1) 로드\n",
    "df = pd.read_csv(IN_PATH)\n",
    "\n",
    "# 2) 필수 컬럼 존재 확인 (실제 파일 기준)\n",
    "required = {\"sido_name\", \"sigungu\", \"year\"}\n",
    "missing = required - set(df.columns)\n",
    "if missing:\n",
    "    raise KeyError(f\"필수 컬럼 누락: {missing}  (파일 컬럼: {list(df.columns)})\")\n",
    "\n",
    "# 3) 정리 & 유일 조합\n",
    "uniq = (\n",
    "    df.loc[:, [\"sido_name\", \"sigungu\", \"year\"]]\n",
    "      .rename(columns={\"sido_name\": \"sido\"})\n",
    "      .assign(\n",
    "          sido=lambda x: x[\"sido\"].astype(str).str.strip(),\n",
    "          sigungu=lambda x: x[\"sigungu\"].astype(str).str.strip(),\n",
    "          year=lambda x: pd.to_numeric(x[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "      )\n",
    "      .dropna(subset=[\"sido\", \"sigungu\", \"year\"])\n",
    "      .drop_duplicates()\n",
    "      .sort_values([\"sido\", \"sigungu\", \"year\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 4) 저장\n",
    "uniq.to_csv(OUT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"[OK] unique_pop.csv saved: {OUT_PATH}  rows={len(uniq):,}\")\n",
    "print(uniq.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d0306",
   "metadata": {},
   "source": [
    "## Construct Matching Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "180f7974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] code_key rows=602, unique join_key=602\n",
      "[OK] Master saved: /Users/kjh/Documents/geostat3_e9/matching_table_join_keys.csv rows=3,926 cols=14\n",
      "[OK] Unmatched (e9): 21 -> /Users/kjh/Documents/geostat3_e9/unmatched_rows_e9.csv\n",
      "[OK] Unmatched (pop): 82 -> /Users/kjh/Documents/geostat3_e9/unmatched_rows_pop.csv\n",
      "[OK] Unmatched (trade): 53 -> /Users/kjh/Documents/geostat3_e9/unmatched_rows_trade.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "매칭 테이블 생성 (시군구 × 연-월 조인키)\n",
    "- 코드북: adm_code_general_2024.xlsx (sheet='Transform')\n",
    "- 소스: unique_e9.csv, unique_pop.csv, unique_trade.csv, (옵션) unique_manufacturing.csv\n",
    "\n",
    "출력:\n",
    "  - matching_table_join_keys.csv\n",
    "  - unmatched_rows_<src>.csv\n",
    "\n",
    "포인트\n",
    "- 시도+시군구 복합키(join_key)로 1차 매칭\n",
    "- Transform 시트의 대체명칭 열들을 이용해 code_key를 확장\n",
    "- 강원/전북 특별자치도 등 시도 별칭 정규화\n",
    "- (중요) 소스의 sigungu가 '서울특별시 강남구' 같은 형태면 시도 접두어 제거\n",
    "- 소스/코드 모두 숫자 프리픽스('11000 서울특별시') 제거\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# -----------------------------\n",
    "# 경로 & 소스\n",
    "# -----------------------------\n",
    "BASE = Path(\"/Users/kjh/Documents/geostat3_e9\")\n",
    "CODEBOOK_XLSX = BASE / \"adm_code_general_2024.xlsx\"\n",
    "SOURCES = {\n",
    "    \"e9\":   BASE / \"unique_e9.csv\",\n",
    "    \"pop\":  BASE / \"unique_pop.csv\",\n",
    "    \"trade\":BASE / \"unique_trade.csv\",\n",
    "    # \"manufacturing\": BASE / \"unique_manufacturing.csv\",\n",
    "}\n",
    "\n",
    "# (옵션) 연도 필터\n",
    "YEAR_START = 2009   # 예: 2009\n",
    "YEAR_END   = None   # 예: 2025\n",
    "\n",
    "# -----------------------------\n",
    "# 유틸\n",
    "# -----------------------------\n",
    "def normalize_korean(text: str) -> str:\n",
    "    \"\"\"공백/괄호 제거 + NFC 정규화\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    s = unicodedata.normalize(\"NFC\", str(text)).strip()\n",
    "    s = re.sub(r\"\\s+\", \"\", s)\n",
    "    s = re.sub(r\"[()（）\\[\\]]\", \"\", s)\n",
    "    return s\n",
    "\n",
    "SIDO_ALIAS = {\n",
    "    normalize_korean(\"강원도\"):          normalize_korean(\"강원특별자치도\"),\n",
    "    normalize_korean(\"강원특별자치도\"):  normalize_korean(\"강원특별자치도\"),\n",
    "    normalize_korean(\"전라북도\"):        normalize_korean(\"전북특별자치도\"),\n",
    "    normalize_korean(\"전북특별자치도\"):  normalize_korean(\"전북특별자치도\"),\n",
    "    normalize_korean(\"전북\"):            normalize_korean(\"전북특별자치도\"),\n",
    "    normalize_korean(\"세종시\"):          normalize_korean(\"세종특별자치시\"),\n",
    "    normalize_korean(\"세종특별자치시\"):  normalize_korean(\"세종특별자치시\"),\n",
    "    normalize_korean(\"제주도\"):          normalize_korean(\"제주특별자치도\"),\n",
    "    normalize_korean(\"제주특별자치도\"):  normalize_korean(\"제주특별자치도\"),\n",
    "}\n",
    "\n",
    "def canonicalize_sido(s: str) -> str:\n",
    "    if pd.isna(s):\n",
    "        return s\n",
    "    s_norm = normalize_korean(s)\n",
    "    return SIDO_ALIAS.get(s_norm, s_norm)\n",
    "\n",
    "def clean_sido_name(x: str) -> str:\n",
    "    \"\"\"'001 서울특별시' → '서울특별시'\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    return re.sub(r\"^\\s*\\d+\\s*\", \"\", str(x)).strip()\n",
    "\n",
    "def digits(s):\n",
    "    return re.sub(r\"[^0-9]\", \"\", str(s)) if pd.notna(s) else \"\"\n",
    "\n",
    "def coerce_yyyymm(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"date/yyyymm/ym/연월 → 6자리 추출, 없으면 year+month, 없으면 year*100+01\"\"\"\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "    for k in [\"date\", \"yyyymm\", \"ym\", \"연월\", \"year_month\"]:\n",
    "        if k in cols_lower:\n",
    "            s = df[cols_lower[k]].astype(str).str.replace(r\"[^0-9]\", \"\", regex=True).str[:6]\n",
    "            s = s.replace(\"\", np.nan)\n",
    "            return s.astype(\"Int64\")\n",
    "    ycol = next((cols_lower[k] for k in [\"year\", \"연도\", \"yyyy\", \"yr\"] if k in cols_lower), None)\n",
    "    mcol = next((cols_lower[k] for k in [\"month\", \"월\", \"mm\", \"mnth\"] if k in cols_lower), None)\n",
    "    if ycol and mcol:\n",
    "        yy = pd.to_numeric(df[ycol], errors=\"coerce\").astype(\"Int64\")\n",
    "        mm = pd.to_numeric(df[mcol], errors=\"coerce\").astype(\"Int64\")\n",
    "        return (yy * 100 + mm).astype(\"Int64\")\n",
    "    if ycol:\n",
    "        yy = pd.to_numeric(df[ycol], errors=\"coerce\").astype(\"Int64\")\n",
    "        return (yy * 100 + 1).astype(\"Int64\")\n",
    "    raise ValueError(\"연-월(yyyymm) 정보를 유추할 수 없습니다.\")\n",
    "\n",
    "def strip_leading_digits(x: str) -> str:\n",
    "    \"\"\"앞 숫자 토큰 제거: '11000 서울특별시' → '서울특별시'\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    return re.sub(r\"^\\s*\\d+\\s*\", \"\", str(x)).strip()\n",
    "\n",
    "def strip_city_prefix(sigungu_norm: str, sido_norm: str) -> str:\n",
    "    \"\"\"\n",
    "    '서울특별시강남구' → '강남구' (이미 normalize된 문자열 기준)\n",
    "    시도명과 완전히 같은 경우(세종특별자치시 등)는 그대로 둠.\n",
    "    \"\"\"\n",
    "    if pd.isna(sigungu_norm) or pd.isna(sido_norm):\n",
    "        return sigungu_norm\n",
    "    sgg = str(sigungu_norm); sido = str(sido_norm)\n",
    "    if sgg == sido:\n",
    "        return sgg\n",
    "    return sgg[len(sido):] if sgg.startswith(sido) else sgg\n",
    "\n",
    "# -----------------------------\n",
    "# 코드북 Transform → code_key 확장\n",
    "# -----------------------------\n",
    "code = pd.read_excel(CODEBOOK_XLSX, sheet_name=\"Transform\", dtype=str).rename(columns=str.strip)\n",
    "\n",
    "# 기본 키(주명칭)\n",
    "base = code[[\"SIDO\",\"SGGNM_ADM\",\"SGGCD_ADM_2024\",\"SGIS_2019\"]].copy()\n",
    "base[\"sido_name\"]    = base[\"SIDO\"].map(clean_sido_name)\n",
    "base[\"sido_norm\"]    = base[\"sido_name\"].map(normalize_korean).map(canonicalize_sido)\n",
    "base[\"sigungu_name\"] = base[\"SGGNM_ADM\"].astype(str).map(strip_leading_digits)\n",
    "base[\"sigungu_norm\"] = base[\"sigungu_name\"].map(normalize_korean)\n",
    "base[\"sgg_code10\"]   = base[\"SGGCD_ADM_2024\"].map(digits)\n",
    "base[\"sgis7_2019\"]   = base[\"SGIS_2019\"].map(digits)\n",
    "\n",
    "# 대체 명칭을 키로 확장\n",
    "ALT_SIG_COLS = [\n",
    "    \"SIGUNGU_NM\",\"SIGUNGU\",\"SIGUNGU_SUB_NM\",\"SIGUNGU_PSEUDO\",\"SIGUNGU_PSEUDO0\",\n",
    "    \"SGGNM_DOJ\",\"SGGNM_DCNM\"\n",
    "]\n",
    "alts = []\n",
    "for c in ALT_SIG_COLS:\n",
    "    if c in code.columns:\n",
    "        t = code[[\"SIDO\", c, \"SGGCD_ADM_2024\", \"SGIS_2019\"]].copy()\n",
    "        t = t.rename(columns={c: \"alt_sigungu\"})\n",
    "        t[\"sido_name\"]    = t[\"SIDO\"].map(clean_sido_name)\n",
    "        t[\"sido_norm\"]    = t[\"sido_name\"].map(normalize_korean).map(canonicalize_sido)\n",
    "        t[\"sigungu_name\"] = t[\"alt_sigungu\"].astype(str).map(strip_leading_digits)\n",
    "        t[\"sigungu_norm\"] = t[\"sigungu_name\"].map(normalize_korean)\n",
    "        t[\"sgg_code10\"]   = t[\"SGGCD_ADM_2024\"].map(digits)\n",
    "        t[\"sgis7_2019\"]   = t[\"SGIS_2019\"].map(digits)\n",
    "        alts.append(t[[\"sido_norm\",\"sigungu_norm\",\"sido_name\",\"sigungu_name\",\"sgg_code10\",\"sgis7_2019\"]])\n",
    "\n",
    "code_key = pd.concat(\n",
    "    [base[[\"sido_norm\",\"sigungu_norm\",\"sido_name\",\"sigungu_name\",\"sgg_code10\",\"sgis7_2019\"]]] + alts,\n",
    "    ignore_index=True\n",
    ")\n",
    "# 키 구성\n",
    "code_key = code_key.dropna(subset=[\"sigungu_norm\"])\n",
    "code_key[\"join_key\"] = (code_key[\"sido_norm\"] + \"::\" + code_key[\"sigungu_norm\"]).astype(\"string\")\n",
    "code_key = code_key.drop_duplicates(subset=[\"join_key\"]).reset_index(drop=True)\n",
    "\n",
    "# 전국에서 시군구명이 유일한 경우(보조 매칭용)\n",
    "unique_sigungu = code_key.groupby(\"sigungu_norm\")[\"sgg_code10\"].nunique().rename(\"n_code\").reset_index()\n",
    "sigungu_unique_only = (\n",
    "    code_key.merge(unique_sigungu, on=\"sigungu_norm\", how=\"left\")\n",
    "            .query(\"n_code == 1\")[[\"sigungu_norm\",\"sgg_code10\",\"sgis7_2019\",\"sido_name\",\"sigungu_name\"]]\n",
    "            .drop_duplicates()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 소스 로드 & 매칭\n",
    "# -----------------------------\n",
    "def load_source(src_name: str, path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, dtype=str)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    if \"sigungu\" not in df.columns:\n",
    "        raise ValueError(f\"[{src_name}] 'sigungu' 컬럼이 필요합니다.\")\n",
    "    if \"sido\" not in df.columns:\n",
    "        df[\"sido\"] = np.nan\n",
    "\n",
    "    # 숫자 프리픽스 제거(혼용 대비), 정규화, 시도 별칭, 시도 접두어 제거\n",
    "    sido_raw    = df[\"sido\"].map(strip_leading_digits).astype(\"string\")\n",
    "    sigungu_raw = df[\"sigungu\"].map(strip_leading_digits).astype(\"string\")\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"sido_raw\":    sido_raw,\n",
    "        \"sigungu_raw\": sigungu_raw,\n",
    "    })\n",
    "    out[\"sido_norm\"]    = out[\"sido_raw\"].map(normalize_korean).map(canonicalize_sido).astype(\"string\")\n",
    "    out[\"sigungu_norm\"] = out[\"sigungu_raw\"].map(normalize_korean).astype(\"string\")\n",
    "    # 특별시/광역시 접두어 제거 (예: '서울특별시강남구' → '강남구')\n",
    "    out[\"sigungu_norm\"] = pd.Series(\n",
    "        [strip_city_prefix(sgg, sido) for sgg, sido in zip(out[\"sigungu_norm\"], out[\"sido_norm\"])],\n",
    "        dtype=\"string\"\n",
    "    )\n",
    "\n",
    "    out[\"join_key\"] = (out[\"sido_norm\"] + \"::\" + out[\"sigungu_norm\"]).astype(\"string\")\n",
    "    out[\"yyyymm\"]   = coerce_yyyymm(df).astype(\"Int64\")\n",
    "    out[\"src\"]      = src_name\n",
    "\n",
    "    if YEAR_START is not None or YEAR_END is not None:\n",
    "        yy = (out[\"yyyymm\"] // 100).astype(\"Int64\")\n",
    "        if YEAR_START is not None:\n",
    "            out = out[yy >= YEAR_START]\n",
    "        if YEAR_END is not None:\n",
    "            out = out[yy <= YEAR_END]\n",
    "\n",
    "    return out.drop_duplicates(subset=[\"join_key\",\"yyyymm\"]).reset_index(drop=True)\n",
    "\n",
    "loaded = {src: load_source(src, path) for src, path in SOURCES.items()}\n",
    "\n",
    "matched_frames = {}\n",
    "unmatched_frames = {}\n",
    "\n",
    "for src, df in loaded.items():\n",
    "    # 1차: 복합키로 정확 매칭\n",
    "    m1 = df.merge(\n",
    "        code_key[[\"join_key\",\"sgg_code10\",\"sgis7_2019\",\"sido_name\",\"sigungu_name\"]],\n",
    "        on=\"join_key\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    # 2차: 1차 실패분 → 전국 유일 시군구명으로 보조 매칭\n",
    "    need_fb = m1[m1[\"sgg_code10\"].isna()].copy()\n",
    "    if not need_fb.empty:\n",
    "        fb = need_fb.merge(sigungu_unique_only, on=\"sigungu_norm\", how=\"left\", suffixes=(\"\", \"_fb\"))\n",
    "        for col in [\"sgg_code10\",\"sgis7_2019\",\"sido_name\",\"sigungu_name\"]:\n",
    "            m1.loc[fb.index, col] = m1.loc[fb.index, col].fillna(fb[col])\n",
    "\n",
    "    matched   = m1[m1[\"sgg_code10\"].notna()].copy()\n",
    "    unmatched = m1[m1[\"sgg_code10\"].isna()].copy()\n",
    "\n",
    "    matched_frames[src] = matched[\n",
    "        [\"sgg_code10\",\"sgis7_2019\",\"yyyymm\",\"sido_raw\",\"sigungu_raw\",\"sido_name\",\"sigungu_name\"]\n",
    "    ].rename(columns={\"sido_raw\": f\"sido_{src}\", \"sigungu_raw\": f\"sigungu_{src}\"})\n",
    "\n",
    "    unmatched_frames[src] = (\n",
    "        unmatched[[\"yyyymm\",\"sido_raw\",\"sigungu_raw\"]]\n",
    "        .rename(columns={\"sido_raw\": \"sido\", \"sigungu_raw\": \"sigungu\"})\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# 마스터(와이드) 구성 & 저장\n",
    "# -----------------------------\n",
    "master = None\n",
    "for src, mf in matched_frames.items():\n",
    "    master = mf.copy() if master is None else master.merge(\n",
    "        mf,\n",
    "        on=[\"sgg_code10\",\"sgis7_2019\",\"yyyymm\",\"sido_name\",\"sigungu_name\"],\n",
    "        how=\"outer\"\n",
    "    )\n",
    "\n",
    "for src in matched_frames.keys():\n",
    "    master[f\"present_{src}\"] = master[f\"sigungu_{src}\"].notna().astype(int)\n",
    "\n",
    "master = master.sort_values([\"sgg_code10\",\"yyyymm\"]).reset_index(drop=True)\n",
    "\n",
    "out_master = BASE / \"matching_table_join_keys.csv\"\n",
    "master.to_csv(out_master, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "for src, uf in unmatched_frames.items():\n",
    "    out_unmatched = BASE / f\"unmatched_rows_{src}.csv\"\n",
    "    (uf.sort_values([\"yyyymm\",\"sigungu\"])\n",
    "       .drop_duplicates()\n",
    "       .to_csv(out_unmatched, index=False, encoding=\"utf-8-sig\"))\n",
    "\n",
    "print(f\"[OK] code_key rows={len(code_key):,}, unique join_key={code_key['join_key'].nunique():,}\")\n",
    "print(f\"[OK] Master saved: {out_master} rows={len(master):,} cols={len(master.columns)}\")\n",
    "for src, uf in unmatched_frames.items():\n",
    "    print(f\"[OK] Unmatched ({src}): {len(uf):,} -> {BASE / f'unmatched_rows_{src}.csv'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83788b7f",
   "metadata": {},
   "source": [
    "### 특이값 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "215d7835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the actual columns from matching_table_join_keys.csv to compute the requested outputs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "path = \"/Users/kjh/Documents/geostat3_e9/matching_table_join_keys.csv\"\n",
    "master = pd.read_csv(path)\n",
    "\n",
    "# Normalize year from yyyymm (use first 4 digits)\n",
    "master = master.copy()\n",
    "master['year'] = master['yyyymm'].astype(str).str.slice(0,4).astype(int)\n",
    "\n",
    "in_range = master['year'].between(2009, 2025)\n",
    "code_col = 'sgg_code10'\n",
    "present_cols = ['present_e9', 'present_pop', 'present_trade']\n",
    "\n",
    "# Build full grid code × year\n",
    "codes = master.loc[in_range, code_col].dropna().unique()\n",
    "years = np.arange(2009, 2026, dtype=int)\n",
    "full_grid = pd.MultiIndex.from_product([codes, years], names=[code_col, 'year']).to_frame(index=False)\n",
    "\n",
    "# Observed (code, year) pairs\n",
    "seen = master.loc[in_range, [code_col, 'year']].drop_duplicates()\n",
    "\n",
    "# Missing pairs\n",
    "missing_pairs = (\n",
    "    full_grid\n",
    "    .merge(seen, on=[code_col, 'year'], how='left', indicator=True)\n",
    "    .query(\"_merge == 'left_only'\")\n",
    "    .drop(columns=\"_merge\")\n",
    "    .sort_values([code_col, 'year'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Attach names for missing_pairs:\n",
    "# 1) Try exact (code, year) mapping from master if exists\n",
    "name_map_cy = (\n",
    "    master.loc[in_range, [code_col, 'year', 'sido_name', 'sigungu_name']]\n",
    "    .dropna(subset=[code_col, 'year'])\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "missing_pairs = missing_pairs.merge(\n",
    "    name_map_cy, on=[code_col, 'year'], how='left'\n",
    ")\n",
    "\n",
    "# 2) For any remaining NaNs, fill by most frequent name per code across available years\n",
    "name_map_code = (\n",
    "    master.loc[in_range, [code_col, 'sido_name', 'sigungu_name']]\n",
    "    .dropna(subset=[code_col])\n",
    ")\n",
    "\n",
    "def mode_or_first(series):\n",
    "    if series.isna().all():\n",
    "        return pd.NA\n",
    "    counts = Counter(series.dropna())\n",
    "    # Return the most common value; deterministic tie-break by value\n",
    "    most_common = sorted(counts.items(), key=lambda x: (-x[1], str(x[0])))[0][0]\n",
    "    return most_common\n",
    "\n",
    "fallback = name_map_code.groupby(code_col).agg({\n",
    "    'sido_name': mode_or_first,\n",
    "    'sigungu_name': mode_or_first\n",
    "}).reset_index().rename(columns={\n",
    "    'sido_name': 'sido_name_fallback',\n",
    "    'sigungu_name': 'sigungu_name_fallback'\n",
    "})\n",
    "\n",
    "missing_pairs = missing_pairs.merge(fallback, on=code_col, how='left')\n",
    "\n",
    "for col in ['sido_name', 'sigungu_name']:\n",
    "    missing_pairs[col] = missing_pairs[col].fillna(missing_pairs[f\"{col}_fallback\"])\n",
    "    missing_pairs.drop(columns=[f\"{col}_fallback\"], inplace=True)\n",
    "\n",
    "# Reorder columns\n",
    "missing_pairs = missing_pairs[[code_col, 'sido_name', 'sigungu_name', 'year']]\n",
    "\n",
    "# Rows where present_* not all 1 (keep names)\n",
    "not_all_one = (\n",
    "    master.loc[in_range]\n",
    "    .loc[lambda d: d[present_cols].ne(1).any(axis=1),\n",
    "         [code_col, 'sido_name', 'sigungu_name', 'yyyymm', 'year'] + present_cols]\n",
    "    .sort_values([code_col, 'year'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Save outputs for download and also preview in UI\n",
    "out1 = \"/Users/kjh/Documents/geostat3_e9/missing_code_year_pairs_2009_2025.csv\"\n",
    "out2 = \"/Users/kjh/Documents/geostat3_e9/not_all_one_present_rows_2009_2025.csv\"\n",
    "missing_pairs.to_csv(out1, index=False, encoding=\"utf-8-sig\")\n",
    "not_all_one.to_csv(out2, index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8f2bf7",
   "metadata": {},
   "source": [
    "- 당진: 군+시 합산\n",
    "- 여주: 군/시 -> 시\n",
    "- 포천: 군/시 -> 시\n",
    "- 연기: 연기/세종시 -> 세종시\n",
    "- 군위: 경북/대구 -> 대구\n",
    "- 청원: 청주와 합산\n",
    "- 인천 남구: 남구/미추홀구 -> 미추홀구\n",
    "- 마산/진해: 창원과 합산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f67058",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2944f722",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ba835d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45933, 13),\n",
       "    canon_sido_name canon_sigungu_name canon_group_id  yyyymm    e9  \\\n",
       " 12         강원특별자치도                강릉시   강원특별자치도::강릉시  200901   0.0   \n",
       " 13         강원특별자치도                강릉시   강원특별자치도::강릉시  200902   0.0   \n",
       " 14         강원특별자치도                강릉시   강원특별자치도::강릉시  200903   0.0   \n",
       " 15         강원특별자치도                강릉시   강원특별자치도::강릉시  200904   0.0   \n",
       " 16         강원특별자치도                강릉시   강원특별자치도::강릉시  200905   0.0   \n",
       " 17         강원특별자치도                강릉시   강원특별자치도::강릉시  200906  83.0   \n",
       " 18         강원특별자치도                강릉시   강원특별자치도::강릉시  200907   0.0   \n",
       " 19         강원특별자치도                강릉시   강원특별자치도::강릉시  200908   0.0   \n",
       " 20         강원특별자치도                강릉시   강원특별자치도::강릉시  200909   0.0   \n",
       " 21         강원특별자치도                강릉시   강원특별자치도::강릉시  200910   0.0   \n",
       " 22         강원특별자치도                강릉시   강원특별자치도::강릉시  200911   0.0   \n",
       " 23         강원특별자치도                강릉시   강원특별자치도::강릉시  200912  94.0   \n",
       " \n",
       "     population_total  population_male  population_female  trade_export_cnt  \\\n",
       " 12               0.0              0.0                0.0              76.0   \n",
       " 13               0.0              0.0                0.0              92.0   \n",
       " 14               0.0              0.0                0.0             109.0   \n",
       " 15               0.0              0.0                0.0             121.0   \n",
       " 16               0.0              0.0                0.0              86.0   \n",
       " 17               0.0              0.0                0.0              99.0   \n",
       " 18               0.0              0.0                0.0             109.0   \n",
       " 19               0.0              0.0                0.0             109.0   \n",
       " 20               0.0              0.0                0.0             121.0   \n",
       " 21               0.0              0.0                0.0             108.0   \n",
       " 22               0.0              0.0                0.0             126.0   \n",
       " 23          217464.0         108146.0           109318.0             143.0   \n",
       " \n",
       "     trade_export_val  trade_import_cnt  trade_import_val  trade_balance  \n",
       " 12            6204.0             248.0           14806.0        -8602.0  \n",
       " 13            5704.0             323.0            4663.0         1040.0  \n",
       " 14            5631.0             326.0           18709.0       -13078.0  \n",
       " 15            8810.0             378.0            2860.0         5950.0  \n",
       " 16            7746.0             392.0            7549.0          197.0  \n",
       " 17            8653.0             393.0            5899.0         2754.0  \n",
       " 18            7979.0             449.0           17935.0        -9956.0  \n",
       " 19            9096.0             412.0           10679.0        -1583.0  \n",
       " 20            8941.0             463.0            8201.0          740.0  \n",
       " 21           10021.0             480.0            9225.0          796.0  \n",
       " 22           12413.0             512.0            8444.0         3969.0  \n",
       " 23           13344.0             465.0           11021.0         2323.0  )"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuild the monthly joined panel with **time-agnostic** canonical mapping,\n",
    "# as requested: always map historical/future records to the same canonical unit.\n",
    "#  - 2+→1 cases (Dangjin, Cheongju, Changwon) → **sum values** into the canonical unit\n",
    "#  - 1→1 cases (Yeoju, Pocheon, Sejong, Michuhol, Gunwi) → **rename only**\n",
    "#\n",
    "# Inputs (uploaded):\n",
    "#   /mnt/data/matching_table_join_keys.csv\n",
    "#   /mnt/data/E9_panel_sgg_aggregated.csv\n",
    "#   /mnt/data/population_panel_sgg_aggregated.csv\n",
    "#   /mnt/data/trade_panel.csv\n",
    "# Output:\n",
    "#   /mnt/data/panel_sgg_monthly_canonical_alltime.csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import unicodedata, re\n",
    "\n",
    "BASE = Path(\"/Users/kjh/Documents/geostat3_e9\")\n",
    "PATH_MT   = BASE / \"matching_table_join_keys.csv\"\n",
    "PATH_E9   = BASE / \"E9_panel_sgg_aggregated.csv\"\n",
    "PATH_POP  = BASE / \"population_panel_sgg_aggregated.csv\"\n",
    "PATH_TR   = BASE / \"trade_panel.csv\"\n",
    "OUT_PATH  = BASE / \"panel_sgg_monthly.csv\"\n",
    "\n",
    "def nrm(s):\n",
    "    if pd.isna(s): return s\n",
    "    s = unicodedata.normalize(\"NFC\", str(s)).strip()\n",
    "    s = re.sub(r\"\\s+\",\"\", s)\n",
    "    s = re.sub(r\"[()（）\\[\\]]\",\"\", s)\n",
    "    return s\n",
    "\n",
    "# Load matching table\n",
    "mt = pd.read_csv(PATH_MT, dtype=str).rename(columns=str.strip)\n",
    "\n",
    "# Build source-priority names (pop -> e9 -> trade) to tag sgg_code10 with a representative (sido, sigungu)\n",
    "has_pop   = {\"sido_pop\",\"sigungu_pop\"}.issubset(mt.columns)\n",
    "has_e9    = {\"sido_e9\",\"sigungu_e9\"}.issubset(mt.columns)\n",
    "has_trade = {\"sido_trade\",\"sigungu_trade\"}.issubset(mt.columns)\n",
    "\n",
    "def pick_name(r):\n",
    "    if has_pop   and pd.notna(r.get(\"sido_pop\"))   and pd.notna(r.get(\"sigungu_pop\")):   return r[\"sido_pop\"], r[\"sigungu_pop\"]\n",
    "    if has_e9    and pd.notna(r.get(\"sido_e9\"))    and pd.notna(r.get(\"sigungu_e9\")):    return r[\"sido_e9\"],  r[\"sigungu_e9\"]\n",
    "    if has_trade and pd.notna(r.get(\"sido_trade\")) and pd.notna(r.get(\"sigungu_trade\")): return r[\"sido_trade\"], r[\"sigungu_trade\"]\n",
    "    return None, None\n",
    "\n",
    "mt[\"src_sido\"], mt[\"src_sigungu\"] = zip(*mt.apply(pick_name, axis=1))\n",
    "rep = (mt.dropna(subset=[\"sgg_code10\",\"src_sido\",\"src_sigungu\"])\n",
    "         .groupby(\"sgg_code10\")[[\"src_sido\",\"src_sigungu\"]]\n",
    "         .agg(lambda col: col.value_counts().index[0])\n",
    "         .reset_index())\n",
    "\n",
    "# Build (sido,sigungu) -> sgg_code10 maps by source\n",
    "def most_frequent_code(df: pd.DataFrame, cs: str, cg: str) -> pd.DataFrame:\n",
    "    if cs not in df.columns or cg not in df.columns:\n",
    "        return pd.DataFrame(columns=[\"sido_norm\",\"sigungu_norm\",\"sgg_code10\"])\n",
    "    tmp = df[[cs, cg, \"sgg_code10\"]].dropna()\n",
    "    if tmp.empty: \n",
    "        return pd.DataFrame(columns=[\"sido_norm\",\"sigungu_norm\",\"sgg_code10\"])\n",
    "    tmp[\"sido_norm\"]    = tmp[cs].map(nrm)\n",
    "    tmp[\"sigungu_norm\"] = tmp[cg].map(nrm)\n",
    "    mapdf = (tmp.groupby([\"sido_norm\",\"sigungu_norm\"])[\"sgg_code10\"]\n",
    "                .agg(lambda s: s.value_counts().index[0]).reset_index())\n",
    "    return mapdf[[\"sido_norm\",\"sigungu_norm\",\"sgg_code10\"]].drop_duplicates()\n",
    "\n",
    "map_e9    = most_frequent_code(mt, \"sido_e9\",   \"sigungu_e9\")\n",
    "map_pop   = most_frequent_code(mt, \"sido_pop\",  \"sigungu_pop\")\n",
    "map_trade = most_frequent_code(mt, \"sido_trade\",\"sigungu_trade\")\n",
    "\n",
    "# Time-agnostic canonical mapping rules\n",
    "SET_DANGJIN  = {\"당진군\",\"당진시\"}\n",
    "SET_CHEONGJU = {\"청원군\",\"청주시\",\"청원\"}\n",
    "SET_CHANGWON = {\"창원시\",\"마산시\",\"진해시\",\"마산\",\"진해\",\"마산합포구\",\"마산회원구\",\"진해구\",\"성산구\",\"의창구\"}\n",
    "\n",
    "SET_MICHHOL  = {\"남구\",\"미추홀구\"}\n",
    "SET_SEJONG   = {\"연기\",\"연기군\",\"세종시\"}\n",
    "SET_GUNWI    = {\"군위\",\"군위군\"}\n",
    "SET_YEOJU    = {\"여주군\",\"여주시\"}\n",
    "SET_POCHEON  = {\"포천군\",\"포천시\"}\n",
    "\n",
    "def canon_name_alltime(sido, sgg):\n",
    "    sdn = nrm(sido) if pd.notna(sido) else None\n",
    "    sgn = nrm(sgg)  if pd.notna(sgg)  else None\n",
    "\n",
    "    # 2+→1 (sum) groups: always map to canonical titles\n",
    "    if sgn in SET_DANGJIN:   return \"충청남도\",\"당진시\"\n",
    "    if sgn in SET_CHEONGJU:  return \"충청북도\",\"청주시\"\n",
    "    if sgn in SET_CHANGWON:  return \"경상남도\",\"창원시\"\n",
    "\n",
    "    # 1→1 (rename only) groups: always map to canonical titles\n",
    "    if (sgn in SET_SEJONG) or (sdn in {\"세종특별자치시\",\"세종시\"}):\n",
    "        return \"세종특별자치시\",\"세종시\"\n",
    "    if sdn == \"인천광역시\" and (sgn in SET_MICHHOL):\n",
    "        return \"인천광역시\",\"미추홀구\"\n",
    "    if sgn in SET_GUNWI:\n",
    "        return \"대구광역시\",\"군위군\"\n",
    "    if sgn in SET_YEOJU:\n",
    "        return \"경기도\",\"여주시\"\n",
    "    if sgn in SET_POCHEON:\n",
    "        return \"경기도\",\"포천시\"\n",
    "\n",
    "    # default: keep original\n",
    "    return sido, sgg\n",
    "\n",
    "# Load panels\n",
    "e9 = pd.read_csv(PATH_E9, dtype=str).rename(columns={\"value\":\"e9\"})\n",
    "e9[\"yyyymm\"] = pd.to_numeric(e9[\"yyyymm\"], errors=\"coerce\").astype(\"Int64\")\n",
    "e9[\"sido_norm\"]    = e9[\"sido\"].map(nrm)\n",
    "e9[\"sigungu_norm\"] = e9[\"sigungu\"].map(nrm)\n",
    "e9 = e9.merge(map_e9, on=[\"sido_norm\",\"sigungu_norm\"], how=\"inner\")\n",
    "e9_agg = e9.groupby([\"sgg_code10\",\"yyyymm\"], as_index=False)[[\"e9\"]].sum()\n",
    "\n",
    "pop = pd.read_csv(PATH_POP, dtype=str).rename(columns={\"total\":\"population_total\",\n",
    "                                                       \"male\":\"population_male\",\n",
    "                                                       \"female\":\"population_female\"})\n",
    "pop[\"yyyymm\"] = pd.to_numeric(pop[\"yyyymm\"], errors=\"coerce\").astype(\"Int64\")\n",
    "pop[\"sido_norm\"]    = pop[\"sido_name\"].map(nrm)\n",
    "pop[\"sigungu_norm\"] = pop[\"sigungu\"].map(nrm)\n",
    "pop = pop.merge(map_pop, on=[\"sido_norm\",\"sigungu_norm\"], how=\"inner\")\n",
    "pop_agg = pop.groupby([\"sgg_code10\",\"yyyymm\"], as_index=False)[[\"population_total\",\"population_male\",\"population_female\"]].sum()\n",
    "\n",
    "tr = pd.read_csv(PATH_TR, dtype=str)\n",
    "split = tr[\"region\"].str.split(r\"\\s+\", n=1, expand=True)\n",
    "tr[\"sido\"]    = split[0]\n",
    "tr[\"sigungu\"] = split[1]\n",
    "tr[\"yyyymm\"]  = (pd.to_numeric(tr[\"year\"], errors=\"coerce\")*100 + pd.to_numeric(tr[\"month\"], errors=\"coerce\")).astype(\"Int64\")\n",
    "tr = tr.rename(columns={\"export_cnt\":\"trade_export_cnt\",\n",
    "                        \"export_val\":\"trade_export_val\",\n",
    "                        \"import_cnt\":\"trade_import_cnt\",\n",
    "                        \"import_val\":\"trade_import_val\"})\n",
    "for c in [\"trade_export_cnt\",\"trade_export_val\",\"trade_import_cnt\",\"trade_import_val\",\"trade_balance\"]:\n",
    "    tr[c] = pd.to_numeric(tr[c], errors=\"coerce\").fillna(0)\n",
    "tr[\"sido_norm\"]    = tr[\"sido\"].map(nrm)\n",
    "tr[\"sigungu_norm\"] = tr[\"sigungu\"].map(nrm)\n",
    "tr = tr.merge(map_trade, on=[\"sido_norm\",\"sigungu_norm\"], how=\"inner\")\n",
    "tr_agg = tr.groupby([\"sgg_code10\",\"yyyymm\"], as_index=False)[[\"trade_export_cnt\",\"trade_export_val\",\"trade_import_cnt\",\"trade_import_val\",\"trade_balance\"]].sum()\n",
    "\n",
    "# Build full union month grid\n",
    "keys = pd.concat([e9_agg[[\"sgg_code10\",\"yyyymm\"]],\n",
    "                  pop_agg[[\"sgg_code10\",\"yyyymm\"]],\n",
    "                  tr_agg[[\"sgg_code10\",\"yyyymm\"]]], ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Attach representative names & compute canonical (time-agnostic) names\n",
    "keys = keys.merge(rep, on=\"sgg_code10\", how=\"left\")\n",
    "keys[[\"canon_sido_name\",\"canon_sigungu_name\"]] = keys.apply(\n",
    "    lambda r: pd.Series(canon_name_alltime(r[\"src_sido\"], r[\"src_sigungu\"])), axis=1\n",
    ")\n",
    "keys[\"canon_group_id\"] = keys[\"canon_sido_name\"].fillna(\"\") + \"::\" + keys[\"canon_sigungu_name\"].fillna(\"\")\n",
    "keys.loc[keys[\"canon_group_id\"]==\"::\",\"canon_group_id\"] = np.nan\n",
    "\n",
    "# Aggregate each panel to canonical groups on the full union grid\n",
    "def to_canon_full(df: pd.DataFrame, value_cols: list[str]) -> pd.DataFrame:\n",
    "    x = df.merge(keys[[\"sgg_code10\",\"yyyymm\",\"canon_group_id\",\"canon_sido_name\",\"canon_sigungu_name\"]],\n",
    "                 on=[\"sgg_code10\",\"yyyymm\"], how=\"right\")\n",
    "    for c in value_cols:\n",
    "        x[c] = pd.to_numeric(x[c], errors=\"coerce\").fillna(0)\n",
    "    out = (x.groupby([\"canon_group_id\",\"canon_sido_name\",\"canon_sigungu_name\",\"yyyymm\"], as_index=False)[value_cols].sum())\n",
    "    return out\n",
    "\n",
    "e9_canon  = to_canon_full(e9_agg,  [\"e9\"])\n",
    "pop_canon = to_canon_full(pop_agg, [\"population_total\",\"population_male\",\"population_female\"])\n",
    "tr_canon  = to_canon_full(tr_agg,  [\"trade_export_cnt\",\"trade_export_val\",\"trade_import_cnt\",\"trade_import_val\",\"trade_balance\"])\n",
    "\n",
    "# Outer-join all canon panels\n",
    "panel = e9_canon.merge(pop_canon, on=[\"canon_group_id\",\"canon_sido_name\",\"canon_sigungu_name\",\"yyyymm\"], how=\"outer\")\n",
    "panel = panel.merge(tr_canon, on=[\"canon_group_id\",\"canon_sido_name\",\"canon_sigungu_name\",\"yyyymm\"], how=\"outer\")\n",
    "\n",
    "# Order & save\n",
    "ordered = [\n",
    "    \"canon_sido_name\",\"canon_sigungu_name\",\"canon_group_id\",\"yyyymm\",\n",
    "    \"e9\",\n",
    "    \"population_total\",\"population_male\",\"population_female\",\n",
    "    \"trade_export_cnt\",\"trade_export_val\",\"trade_import_cnt\",\"trade_import_val\",\"trade_balance\",\n",
    "]\n",
    "for c in ordered:\n",
    "    if c not in panel.columns:\n",
    "        panel[c] = np.nan\n",
    "panel = panel[ordered].sort_values([\"canon_sido_name\",\"canon_sigungu_name\",\"yyyymm\"]).reset_index(drop=True)\n",
    "panel = panel[pd.to_numeric(panel[\"yyyymm\"], errors=\"coerce\") >= 200901].copy()\n",
    "\n",
    "panel.to_csv(OUT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "panel.shape, panel.head(12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20da869e",
   "metadata": {},
   "source": [
    "시군구코드 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3317bb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45933, 16),\n",
       "    canon_sido_name canon_sigungu_name canon_group_id  yyyymm    e9  \\\n",
       " 0          강원특별자치도                강릉시   강원특별자치도::강릉시  200901   0.0   \n",
       " 1          강원특별자치도                강릉시   강원특별자치도::강릉시  200902   0.0   \n",
       " 2          강원특별자치도                강릉시   강원특별자치도::강릉시  200903   0.0   \n",
       " 3          강원특별자치도                강릉시   강원특별자치도::강릉시  200904   0.0   \n",
       " 4          강원특별자치도                강릉시   강원특별자치도::강릉시  200905   0.0   \n",
       " 5          강원특별자치도                강릉시   강원특별자치도::강릉시  200906  83.0   \n",
       " 6          강원특별자치도                강릉시   강원특별자치도::강릉시  200907   0.0   \n",
       " 7          강원특별자치도                강릉시   강원특별자치도::강릉시  200908   0.0   \n",
       " 8          강원특별자치도                강릉시   강원특별자치도::강릉시  200909   0.0   \n",
       " 9          강원특별자치도                강릉시   강원특별자치도::강릉시  200910   0.0   \n",
       " 10         강원특별자치도                강릉시   강원특별자치도::강릉시  200911   0.0   \n",
       " 11         강원특별자치도                강릉시   강원특별자치도::강릉시  200912  94.0   \n",
       " \n",
       "    population_total population_male population_female trade_export_cnt  \\\n",
       " 0               0.0             0.0               0.0             76.0   \n",
       " 1               0.0             0.0               0.0             92.0   \n",
       " 2               0.0             0.0               0.0            109.0   \n",
       " 3               0.0             0.0               0.0            121.0   \n",
       " 4               0.0             0.0               0.0             86.0   \n",
       " 5               0.0             0.0               0.0             99.0   \n",
       " 6               0.0             0.0               0.0            109.0   \n",
       " 7               0.0             0.0               0.0            109.0   \n",
       " 8               0.0             0.0               0.0            121.0   \n",
       " 9               0.0             0.0               0.0            108.0   \n",
       " 10              0.0             0.0               0.0            126.0   \n",
       " 11         217464.0        108146.0          109318.0            143.0   \n",
       " \n",
       "    trade_export_val trade_import_cnt trade_import_val trade_balance  \\\n",
       " 0            6204.0            248.0          14806.0       -8602.0   \n",
       " 1            5704.0            323.0           4663.0        1040.0   \n",
       " 2            5631.0            326.0          18709.0      -13078.0   \n",
       " 3            8810.0            378.0           2860.0        5950.0   \n",
       " 4            7746.0            392.0           7549.0         197.0   \n",
       " 5            8653.0            393.0           5899.0        2754.0   \n",
       " 6            7979.0            449.0          17935.0       -9956.0   \n",
       " 7            9096.0            412.0          10679.0       -1583.0   \n",
       " 8            8941.0            463.0           8201.0         740.0   \n",
       " 9           10021.0            480.0           9225.0         796.0   \n",
       " 10          12413.0            512.0           8444.0        3969.0   \n",
       " 11          13344.0            465.0          11021.0        2323.0   \n",
       " \n",
       "    _sido_norm _sigungu_norm sgg_code10  \n",
       " 0     강원특별자치도           강릉시      51150  \n",
       " 1     강원특별자치도           강릉시      51150  \n",
       " 2     강원특별자치도           강릉시      51150  \n",
       " 3     강원특별자치도           강릉시      51150  \n",
       " 4     강원특별자치도           강릉시      51150  \n",
       " 5     강원특별자치도           강릉시      51150  \n",
       " 6     강원특별자치도           강릉시      51150  \n",
       " 7     강원특별자치도           강릉시      51150  \n",
       " 8     강원특별자치도           강릉시      51150  \n",
       " 9     강원특별자치도           강릉시      51150  \n",
       " 10    강원특별자치도           강릉시      51150  \n",
       " 11    강원특별자치도           강릉시      51150  ,\n",
       " ['sgg_code10',\n",
       "  'sgis7_2019',\n",
       "  'yyyymm',\n",
       "  'sido_e9',\n",
       "  'sigungu_e9',\n",
       "  'sido_name',\n",
       "  'sigungu_name',\n",
       "  'sido_pop',\n",
       "  'sigungu_pop',\n",
       "  'sido_trade',\n",
       "  'sigungu_trade',\n",
       "  'present_e9',\n",
       "  'present_pop',\n",
       "  'present_trade'],\n",
       " ['canon_sido_name',\n",
       "  'canon_sigungu_name',\n",
       "  'canon_group_id',\n",
       "  'yyyymm',\n",
       "  'e9',\n",
       "  'population_total',\n",
       "  'population_male',\n",
       "  'population_female',\n",
       "  'trade_export_cnt',\n",
       "  'trade_export_val',\n",
       "  'trade_import_cnt',\n",
       "  'trade_import_val',\n",
       "  'trade_balance'],\n",
       " PosixPath('/Users/kjh/Documents/geostat3_e9/panel_sgg_monthly_with_sgg_code10.csv'))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read files, inspect structure, then add `sgg_code10` to panel_sgg_monthly.csv using matching_table_join_keys.csv\n",
    "# - Robust to column name variants\n",
    "# - Saves to /mnt/data/panel_sgg_monthly_with_sgg_code10.csv\n",
    "# - Shows quick previews\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import unicodedata, re\n",
    "from typing import List, Optional\n",
    "\n",
    "BASE = Path(\"/Users/kjh/Documents/geostat3_e9\")\n",
    "PATH_MT   = BASE / \"matching_table_join_keys.csv\"\n",
    "PATH_PAN  = BASE / \"panel_sgg_monthly.csv\"\n",
    "OUT_PATH  = BASE / \"panel_sgg_monthly_with_sgg_code10.csv\"\n",
    "\n",
    "\n",
    "def nrm(s):\n",
    "    if pd.isna(s): return s\n",
    "    s = unicodedata.normalize(\"NFC\", str(s)).strip()\n",
    "    s = re.sub(r\"\\s+\",\"\", s)\n",
    "    s = re.sub(r\"[()（）\\[\\]]\",\"\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def pick_first(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    # try case-insensitive / stripped match\n",
    "    normmap = {c.strip().lower(): c for c in df.columns}\n",
    "    for c in candidates:\n",
    "        key = c.strip().lower()\n",
    "        if key in normmap:\n",
    "            return normmap[key]\n",
    "    return None\n",
    "\n",
    "\n",
    "# 1) Load files ---------------------------------------------------------------\n",
    "mt = pd.read_csv(PATH_MT, dtype=str).rename(columns=lambda x: x.strip())\n",
    "panel = pd.read_csv(PATH_PAN, dtype=str).rename(columns=lambda x: x.strip())\n",
    "\n",
    "# Preview structures\n",
    "preview_mt_cols = list(mt.columns)\n",
    "preview_pan_cols = list(panel.columns)\n",
    "\n",
    "# 2) Build flexible (sido, sigungu) -> sgg_code10 map -------------------------\n",
    "# Ensure sgg_code10 exists even if named differently\n",
    "sgg_candidates = [\"sgg_code10\",\"sgg_code\",\"sgg\",\"sgg_code_10\",\"sggcd10\",\"sgg_cd10\",\"sgg_cd\"]\n",
    "sgg_col = pick_first(mt, sgg_candidates)\n",
    "if sgg_col is None:\n",
    "    raise ValueError(\"matching_table_join_keys.csv에 sgg_code10(혹은 유사명)이 없습니다.\")\n",
    "if sgg_col != \"sgg_code10\":\n",
    "    mt = mt.rename(columns={sgg_col: \"sgg_code10\"})\n",
    "mt[\"sgg_code10\"] = mt[\"sgg_code10\"].astype(str)\n",
    "\n",
    "# Candidate (sido, sigungu) pairs from different sources inside the matching table\n",
    "pair_candidates = [\n",
    "    (\"sido_pop\",\"sigungu_pop\"),\n",
    "    (\"sido_e9\",\"sigungu_e9\"),\n",
    "    (\"sido_trade\",\"sigungu_trade\"),\n",
    "    # Sometimes the matching table may already include a generic (sido, sigungu)\n",
    "    (\"sido\",\"sigungu\"),\n",
    "    (\"sido_name\",\"sigungu_name\"),\n",
    "    (\"src_sido\",\"src_sigungu\"),  # if previously constructed\n",
    "]\n",
    "\n",
    "maps = []\n",
    "for cs, cg in pair_candidates:\n",
    "    if cs in mt.columns and cg in mt.columns:\n",
    "        tmp = mt[[cs, cg, \"sgg_code10\"]].dropna()\n",
    "        if not tmp.empty:\n",
    "            tmp = tmp.assign(\n",
    "                sido_norm = tmp[cs].map(nrm),\n",
    "                sigungu_norm = tmp[cg].map(nrm),\n",
    "            )\n",
    "            # prefer the most frequent code if duplicated\n",
    "            g = (tmp.groupby([\"sido_norm\",\"sigungu_norm\"])[\"sgg_code10\"]\n",
    "                   .agg(lambda s: s.value_counts().index[0]).reset_index())\n",
    "            maps.append(g)\n",
    "\n",
    "if not maps:\n",
    "    raise ValueError(\"매칭 테이블에서 (sido, sigungu) 쌍을 찾을 수 없습니다. 사용 가능한 컬럼을 확인하세요.\")\n",
    "\n",
    "map_union = pd.concat(maps, ignore_index=True).drop_duplicates()\n",
    "# If multiple sgg_code10 per pair slipped through, keep the majority vote\n",
    "map_union = (map_union.groupby([\"sido_norm\",\"sigungu_norm\"])[\"sgg_code10\"]\n",
    "                       .agg(lambda s: s.value_counts().index[0]).reset_index())\n",
    "\n",
    "# 3) Detect (sido, sigungu) in panel and merge --------------------------------\n",
    "sido_col = pick_first(panel, [\"canon_sido_name\",\"sido\",\"sido_name\",\"시도\",\"SIDO\",\"sido_nm\"])\n",
    "sigungu_col = pick_first(panel, [\"canon_sigungu_name\",\"sigungu\",\"sigungu_name\",\"시군구\",\"SGG\",\"sgg\",\"sigungu_nm\"])\n",
    "if not all([sido_col, sigungu_col]):\n",
    "    raise ValueError(\"panel_sgg_monthly.csv에서 (sido, sigungu) 컬럼을 찾지 못했습니다.\")\n",
    "\n",
    "panel[\"_sido_norm\"]    = panel[sido_col].map(nrm)\n",
    "panel[\"_sigungu_norm\"] = panel[sigungu_col].map(nrm)\n",
    "\n",
    "panel2 = panel.merge(\n",
    "    map_union.rename(columns={\"sido_norm\":\"_sido_norm\",\"sigungu_norm\":\"_sigungu_norm\"}),\n",
    "    on=[\"_sido_norm\",\"_sigungu_norm\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 4) Save & show quick checks --------------------------------------------------\n",
    "panel2.to_csv(OUT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "panel2.shape, panel2.head(12), preview_mt_cols, preview_pan_cols, OUT_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ccbeaa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "overrides = {\n",
    "    \"창원시\": \"48120\",\n",
    "    # 필요시 여기 추가: \"청주시\": \"43110\", \"당진시\": \"44270\", ...\n",
    "}\n",
    "panel2[\"sgg_code10\"] = panel2[\"sgg_code10\"].fillna(panel2[\"_sigungu_norm\"].map(overrides))\n",
    "panel2.to_csv(OUT_PATH, index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87248a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45933, 20), PosixPath('/Users/kjh/Documents/geostat3_e9/panel_full.csv'))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/Users/kjh/Documents/geostat3_e9/\")\n",
    "\n",
    "# --- 1. panel2는 이미 메모리에 있다고 가정 (없으면 아래 주석 해제해서 로드)\n",
    "# panel2 = pd.read_csv(BASE / \"panel_sgg_monthly_with_sgg_code10.csv\", dtype=str)\n",
    "\n",
    "# --- 2. Transform 시트 읽기\n",
    "adm = pd.read_excel(\n",
    "    BASE / \"adm_code_general_2024.xlsx\",\n",
    "    sheet_name=\"Transform\",\n",
    "    dtype=str\n",
    ")\n",
    "\n",
    "# 필요한 열만 추출\n",
    "adm_sub = adm[[\"SGGCD_ADM_2024\", \"IMSI_SDCD\", \"SGIS_2024\"]].drop_duplicates()\n",
    "\n",
    "# --- 3. join\n",
    "panel2 = panel2.merge(\n",
    "    adm_sub,\n",
    "    left_on=\"sgg_code10\",\n",
    "    right_on=\"SGGCD_ADM_2024\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# SGIS_2024 앞 5자리만 사용\n",
    "panel2[\"SGIS_2024\"] = panel2[\"SGIS_2024\"].astype(str).str.slice(0, 5)\n",
    "\n",
    "# 컬럼명 변경\n",
    "panel2 = panel2.rename(columns={\n",
    "    \"IMSI_SDCD\": \"sd_code\",\n",
    "    \"SGIS_2024\": \"sgg_code_sgis\"\n",
    "})\n",
    "\n",
    "# --- 4. panel3로 복사 + 중복 컬럼 제거\n",
    "panel3 = panel2.loc[:, ~panel2.columns.duplicated()].copy()\n",
    "\n",
    "# 혹시 그래도 'sgg_code_sgis'가 여러 개 남아 있을 경우 첫 번째 것만 사용\n",
    "sgis_col = panel3[\"sgg_code_sgis\"]\n",
    "if isinstance(sgis_col, pd.DataFrame):           # 동일 이름 컬럼이 여러 개이면 DataFrame\n",
    "    sgis_col = sgis_col.iloc[:, 0]               # 첫 번째 열만 사용\n",
    "sgis_col = sgis_col.astype(str)\n",
    "\n",
    "overrides = {\n",
    "    \"창원시\": \"38110\",\n",
    "    # \"청주시\": \"43110\",\n",
    "    # \"당진시\": \"44270\",\n",
    "    # 필요시 추가\n",
    "}\n",
    "\n",
    "# override용 Series\n",
    "override_series = panel3[\"_sigungu_norm\"].map(overrides)\n",
    "\n",
    "# ① SGIS 코드가 있으면 그대로 사용, 없으면 overrides 사용해서 새 코드 생성\n",
    "panel3[\"sgg_code_sgis\"] = sgis_col.where(sgis_col.notna() & (sgis_col != \"nan\"), override_series)\n",
    "\n",
    "# --- 5. 필요없는 키 컬럼 정리\n",
    "panel3 = panel3.drop(columns=[\"SGGCD_ADM_2024, sgg_code10_from_sgis\"], errors=\"ignore\")\n",
    "\n",
    "# --- 6. 저장\n",
    "OUT_PATH = BASE / \"panel_full.csv\"\n",
    "panel3.to_csv(OUT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "panel3.shape, OUT_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7e1757d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['canon_sido_name', 'canon_sigungu_name', 'canon_group_id', 'yyyymm', 'e9', 'population_total', 'population_male', 'population_female', 'trade_export_cnt', 'trade_export_val', 'trade_import_cnt', 'trade_import_val', 'trade_balance', '_sido_norm', '_sigungu_norm', 'sgg_code10', 'SGGCD_ADM_2024', 'sd_code', 'sgg_code_sgis']\n"
     ]
    }
   ],
   "source": [
    "print(panel3.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcf6d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snustdatasci-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
